

Reading dataset
Dataset read complete...
n users: 75
n items: 3287
Model intialized
Beginning Training...
cuda
mse loss
Training on GPU: 1 devices
iteration: 0 - loss: 12.58727
iteration: 50 - loss: 13.73608
iteration: 100 - loss: 13.97595
iteration: 150 - loss: 13.87824
iteration: 200 - loss: 13.97117
iteration: 250 - loss: 13.73539
iteration: 300 - loss: 13.56921
iteration: 350 - loss: 12.89445
iteration: 400 - loss: 12.15952
iteration: 450 - loss: 11.34082
iteration: 500 - loss: 10.21743
iteration: 550 - loss: 8.20069
iteration: 600 - loss: 6.36179
iteration: 650 - loss: 4.28251
iteration: 700 - loss: 2.78637
iteration: 750 - loss: 1.61255
iteration: 800 - loss: 1.13248
iteration: 850 - loss: 1.01463
iteration: 900 - loss: 0.91191
iteration: 950 - loss: 0.94233
iteration: 1000 - loss: 0.90729
iteration: 1050 - loss: 0.84588
iteration: 1100 - loss: 0.93927
iteration: 1150 - loss: 0.87464
iteration: 1200 - loss: 0.90333
iteration: 1250 - loss: 0.87567
iteration: 1300 - loss: 0.85417
iteration: 1350 - loss: 0.83727
iteration: 1400 - loss: 0.89494
iteration: 1450 - loss: 0.87068
iteration: 1500 - loss: 0.81275
iteration: 1550 - loss: 0.79884
iteration: 1600 - loss: 0.80315
iteration: 1650 - loss: 0.82147
iteration: 1700 - loss: 0.81052
iteration: 1750 - loss: 0.89390
iteration: 1800 - loss: 0.78325
iteration: 1850 - loss: 0.80353
iteration: 1900 - loss: 0.76032
iteration: 1950 - loss: 0.79852
iteration: 2000 - loss: 0.85885
iteration: 2050 - loss: 0.73947
iteration: 2100 - loss: 0.83352
iteration: 2150 - loss: 0.71427
iteration: 2200 - loss: 0.78699
iteration: 2250 - loss: 0.80739
iteration: 2300 - loss: 0.81876
iteration: 2350 - loss: 0.75523
iteration: 2400 - loss: 0.74278
iteration: 2450 - loss: 0.76215
iteration: 2500 - loss: 0.68331
iteration: 2550 - loss: 0.72631
iteration: 2600 - loss: 0.78209
iteration: 2650 - loss: 0.75206
iteration: 2700 - loss: 0.75428
iteration: 2750 - loss: 0.66207
iteration: 2800 - loss: 0.76603
iteration: 2850 - loss: 0.68246
iteration: 2900 - loss: 0.72377
iteration: 2950 - loss: 0.76623
iteration: 3000 - loss: 0.63274
iteration: 3050 - loss: 0.72856
iteration: 3100 - loss: 0.73590
iteration: 3150 - loss: 0.62696
iteration: 3200 - loss: 0.72926
iteration: 3250 - loss: 0.67497
iteration: 3300 - loss: 0.69904
iteration: 3350 - loss: 0.66091
iteration: 3400 - loss: 0.65655
iteration: 3450 - loss: 0.69800
iteration: 3500 - loss: 0.68181
iteration: 3550 - loss: 0.65935
iteration: 3600 - loss: 0.69720
iteration: 3650 - loss: 0.66082
iteration: 3700 - loss: 0.69436
iteration: 3750 - loss: 0.62570
iteration: 3800 - loss: 0.63349
iteration: 3850 - loss: 0.64082
iteration: 3900 - loss: 0.67340
iteration: 3950 - loss: 0.64408
iteration: 4000 - loss: 0.66578
iteration: 4050 - loss: 0.64919
iteration: 4100 - loss: 0.63880
iteration: 4150 - loss: 0.63185
iteration: 4200 - loss: 0.64804
iteration: 4250 - loss: 0.62558
iteration: 4300 - loss: 0.59426
iteration: 4350 - loss: 0.59499
iteration: 4400 - loss: 0.66851
iteration: 4450 - loss: 0.67904
iteration: 4500 - loss: 0.58759
iteration: 4550 - loss: 0.59601
iteration: 4600 - loss: 0.57744
iteration: 4650 - loss: 0.64731
iteration: 4700 - loss: 0.61787
iteration: 4750 - loss: 0.62483
iteration: 4800 - loss: 0.58683
iteration: 4850 - loss: 0.60156
iteration: 4900 - loss: 0.61296
iteration: 4950 - loss: 0.60175
iteration: 5000 - loss: 0.61101
iteration: 5050 - loss: 0.59200
iteration: 5100 - loss: 0.58446
iteration: 5150 - loss: 0.56049
iteration: 5200 - loss: 0.62414
iteration: 5250 - loss: 0.61363
iteration: 5300 - loss: 0.56575
iteration: 5350 - loss: 0.56617
iteration: 5400 - loss: 0.58540
iteration: 5450 - loss: 0.60630
iteration: 5500 - loss: 0.60113
iteration: 5550 - loss: 0.53066
iteration: 5600 - loss: 0.61002
iteration: 5650 - loss: 0.55101
iteration: 5700 - loss: 0.60672
iteration: 5750 - loss: 0.58752
iteration: 5800 - loss: 0.58849
iteration: 5850 - loss: 0.57161
iteration: 5900 - loss: 0.56541
iteration: 5950 - loss: 0.57350
iteration: 6000 - loss: 0.55621
iteration: 6050 - loss: 0.57436
iteration: 6100 - loss: 0.56638
iteration: 6150 - loss: 0.51757
iteration: 6200 - loss: 0.58057
iteration: 6250 - loss: 0.57983
iteration: 6300 - loss: 0.58866
iteration: 6350 - loss: 0.51478
iteration: 6400 - loss: 0.58885
iteration: 6450 - loss: 0.56464
iteration: 6500 - loss: 0.54601
iteration: 6550 - loss: 0.54825
iteration: 6600 - loss: 0.54350
iteration: 6650 - loss: 0.56125
iteration: 6700 - loss: 0.54263
iteration: 6750 - loss: 0.57895
iteration: 6800 - loss: 0.54115
iteration: 6850 - loss: 0.52879
iteration: 6900 - loss: 0.58748
iteration: 6950 - loss: 0.54724
iteration: 7000 - loss: 0.53370
iteration: 7050 - loss: 0.51921
iteration: 7100 - loss: 0.53252
iteration: 7150 - loss: 0.54459
iteration: 7200 - loss: 0.57205
iteration: 7250 - loss: 0.56571
iteration: 7300 - loss: 0.56103
iteration: 7350 - loss: 0.57041
iteration: 7400 - loss: 0.54307
iteration: 7450 - loss: 0.51831
iteration: 7500 - loss: 0.52574
iteration: 7550 - loss: 0.56939
iteration: 7600 - loss: 0.51759
iteration: 7650 - loss: 0.52284
iteration: 7700 - loss: 0.54456
iteration: 7750 - loss: 0.54299
iteration: 7800 - loss: 0.53671
iteration: 7850 - loss: 0.49132
iteration: 7900 - loss: 0.56050
iteration: 7950 - loss: 0.53509
iteration: 8000 - loss: 0.56244
iteration: 8050 - loss: 0.50392
iteration: 8100 - loss: 0.51722
iteration: 8150 - loss: 0.53986
iteration: 8200 - loss: 0.55728
iteration: 8250 - loss: 0.56009
iteration: 8300 - loss: 0.47117
iteration: 8350 - loss: 0.53715
iteration: 8400 - loss: 0.52440
iteration: 8450 - loss: 0.57444
iteration: 8500 - loss: 0.56164
iteration: 8550 - loss: 0.50152
iteration: 8600 - loss: 0.56159
iteration: 8650 - loss: 0.52410
iteration: 8700 - loss: 0.56469
iteration: 8750 - loss: 0.49825
iteration: 8800 - loss: 0.47752
iteration: 8850 - loss: 0.56975
iteration: 8900 - loss: 0.54128
iteration: 8950 - loss: 0.56430
iteration: 9000 - loss: 0.49494
iteration: 9050 - loss: 0.50758
iteration: 9100 - loss: 0.54913
iteration: 9150 - loss: 0.53924
iteration: 9200 - loss: 0.55944
iteration: 9250 - loss: 0.49151
iteration: 9300 - loss: 0.54230
iteration: 9350 - loss: 0.57168
iteration: 9400 - loss: 0.49122
iteration: 9450 - loss: 0.51504
iteration: 9500 - loss: 0.52604
iteration: 9550 - loss: 0.49707
iteration: 9600 - loss: 0.54642
iteration: 9650 - loss: 0.53014
iteration: 9700 - loss: 0.54368
iteration: 9750 - loss: 0.50506
iteration: 9800 - loss: 0.50082
iteration: 9850 - loss: 0.55931
iteration: 9900 - loss: 0.50447
iteration: 9950 - loss: 0.54822
iteration: 10000 - loss: 0.50898
iteration: 10050 - loss: 0.49138
iteration: 10100 - loss: 0.54661
iteration: 10150 - loss: 0.52315
iteration: 10200 - loss: 0.55401
iteration: 10250 - loss: 0.50007
iteration: 10300 - loss: 0.50942
iteration: 10350 - loss: 0.50846
iteration: 10400 - loss: 0.51825
iteration: 10450 - loss: 0.52015
iteration: 10500 - loss: 0.56674
iteration: 10550 - loss: 0.48008
iteration: 10600 - loss: 0.50700
iteration: 10650 - loss: 0.51580
iteration: 10700 - loss: 0.53906
iteration: 10750 - loss: 0.56491
iteration: 10800 - loss: 0.45487
iteration: 10850 - loss: 0.55790
iteration: 10900 - loss: 0.58032
iteration: 10950 - loss: 0.51680
iteration: 11000 - loss: 0.50094
iteration: 11050 - loss: 0.51579
iteration: 11100 - loss: 0.52862
iteration: 11150 - loss: 0.56166
iteration: 11200 - loss: 0.49575
iteration: 11250 - loss: 0.51611
iteration: 11300 - loss: 0.47707
iteration: 11350 - loss: 0.53742
iteration: 11400 - loss: 0.54700
iteration: 11450 - loss: 0.51435
iteration: 11500 - loss: 0.52662
iteration: 11550 - loss: 0.52027
iteration: 11600 - loss: 0.52701
iteration: 11650 - loss: 0.56662
iteration: 11700 - loss: 0.46656
iteration: 11750 - loss: 0.52898
iteration: 11800 - loss: 0.57257
iteration: 11850 - loss: 0.47520
iteration: 11900 - loss: 0.49795
iteration: 11950 - loss: 0.53502
iteration: 12000 - loss: 0.51533
iteration: 12050 - loss: 0.54154
iteration: 12100 - loss: 0.52891
iteration: 12150 - loss: 0.55217
iteration: 12200 - loss: 0.46888
iteration: 12250 - loss: 0.50832
iteration: 12300 - loss: 0.50413
iteration: 12350 - loss: 0.51000
iteration: 12400 - loss: 0.50306
iteration: 12450 - loss: 0.53925
iteration: 12500 - loss: 0.55022
iteration: 12550 - loss: 0.47979
iteration: 12600 - loss: 0.51849
iteration: 12650 - loss: 0.53789
iteration: 12700 - loss: 0.54524
iteration: 12750 - loss: 0.51713
iteration: 12800 - loss: 0.53678
iteration: 12850 - loss: 0.54686
iteration: 12900 - loss: 0.48122
iteration: 12950 - loss: 0.49596
iteration: 13000 - loss: 0.53296
iteration: 13050 - loss: 0.49079
iteration: 13100 - loss: 0.48229
iteration: 13150 - loss: 0.50189
iteration: 13200 - loss: 0.57438
iteration: 13250 - loss: 0.54954
iteration: 13300 - loss: 0.49627
iteration: 13350 - loss: 0.54920
iteration: 13400 - loss: 0.50825
iteration: 13450 - loss: 0.51080
iteration: 13500 - loss: 0.52977
iteration: 13550 - loss: 0.51734
iteration: 13600 - loss: 0.51393
iteration: 13650 - loss: 0.52307
iteration: 13700 - loss: 0.52021
iteration: 13750 - loss: 0.53137
iteration: 13800 - loss: 0.51840
iteration: 13850 - loss: 0.48389
iteration: 13900 - loss: 0.58305
iteration: 13950 - loss: 0.49471
iteration: 14000 - loss: 0.50904
iteration: 14050 - loss: 0.53086
iteration: 14100 - loss: 0.49898
iteration: 14150 - loss: 0.52173
iteration: 14200 - loss: 0.53109
iteration: 14250 - loss: 0.51330
iteration: 14300 - loss: 0.52907
iteration: 14350 - loss: 0.49822
iteration: 14400 - loss: 0.49216
iteration: 14450 - loss: 0.52949
iteration: 14500 - loss: 0.55049
iteration: 14550 - loss: 0.53467
iteration: 14600 - loss: 0.48711
iteration: 14650 - loss: 0.51535
iteration: 14700 - loss: 0.51797
iteration: 14750 - loss: 0.53858
iteration: 14800 - loss: 0.54076
iteration: 14850 - loss: 0.52496
iteration: 14900 - loss: 0.53694
iteration: 14950 - loss: 0.50778
iteration: 15000 - loss: 0.49099
iteration: 15050 - loss: 0.49871
iteration: 15100 - loss: 0.49365
iteration: 15150 - loss: 0.52962
iteration: 15200 - loss: 0.49798
iteration: 15250 - loss: 0.56497
iteration: 15300 - loss: 0.53622
iteration: 15350 - loss: 0.50339
iteration: 15400 - loss: 0.52506
iteration: 15450 - loss: 0.51761
iteration: 15500 - loss: 0.51669
iteration: 15550 - loss: 0.52847
iteration: 15600 - loss: 0.50689
iteration: 15650 - loss: 0.49259
iteration: 15700 - loss: 0.52968
iteration: 15750 - loss: 0.53237
iteration: 15800 - loss: 0.50293
iteration: 15850 - loss: 0.51837
iteration: 15900 - loss: 0.53215
iteration: 15950 - loss: 0.53172
iteration: 16000 - loss: 0.50285
iteration: 16050 - loss: 0.47577
iteration: 16100 - loss: 0.52317
iteration: 16150 - loss: 0.52175
iteration: 16200 - loss: 0.55352
iteration: 16250 - loss: 0.53040
iteration: 16300 - loss: 0.53721
iteration: 16350 - loss: 0.52823
iteration: 16400 - loss: 0.52892
iteration: 16450 - loss: 0.50545
iteration: 16500 - loss: 0.48763
iteration: 16550 - loss: 0.51582
iteration: 16600 - loss: 0.52402
iteration: 16650 - loss: 0.51035
iteration: 16700 - loss: 0.52614
iteration: 16750 - loss: 0.51486
iteration: 16800 - loss: 0.56046
iteration: 16850 - loss: 0.51048
iteration: 16900 - loss: 0.47906
iteration: 16950 - loss: 0.51226
iteration: 17000 - loss: 0.53778
iteration: 17050 - loss: 0.51560
iteration: 17100 - loss: 0.50279
iteration: 17150 - loss: 0.53047
iteration: 17200 - loss: 0.53013
iteration: 17250 - loss: 0.51235
iteration: 17300 - loss: 0.55333
iteration: 17350 - loss: 0.53387
iteration: 17400 - loss: 0.50759
iteration: 17450 - loss: 0.48511
iteration: 17500 - loss: 0.51598
iteration: 17550 - loss: 0.54521
iteration: 17600 - loss: 0.51401
iteration: 17650 - loss: 0.53828
iteration: 17700 - loss: 0.49655
iteration: 17750 - loss: 0.49706
iteration: 17800 - loss: 0.48868
iteration: 17850 - loss: 0.58025
iteration: 17900 - loss: 0.50606
iteration: 17950 - loss: 0.47602
iteration: 18000 - loss: 0.55632
iteration: 18050 - loss: 0.51324
iteration: 18100 - loss: 0.53763
iteration: 18150 - loss: 0.53532
iteration: 18200 - loss: 0.46917
iteration: 18250 - loss: 0.53174
iteration: 18300 - loss: 0.49992
iteration: 18350 - loss: 0.48917
iteration: 18400 - loss: 0.49994
iteration: 18450 - loss: 0.55698
iteration: 18500 - loss: 0.54657
iteration: 18550 - loss: 0.47619
iteration: 18600 - loss: 0.51458
iteration: 18650 - loss: 0.53462
iteration: 18700 - loss: 0.53527
iteration: 18750 - loss: 0.52855
iteration: 18800 - loss: 0.47388
iteration: 18850 - loss: 0.46975
iteration: 18900 - loss: 0.56113
iteration: 18950 - loss: 0.53824
iteration: 19000 - loss: 0.54701
iteration: 19050 - loss: 0.52844
iteration: 19100 - loss: 0.48464
iteration: 19150 - loss: 0.53157
iteration: 19200 - loss: 0.51057
iteration: 19250 - loss: 0.54353
iteration: 19300 - loss: 0.50328
iteration: 19350 - loss: 0.49107
iteration: 19400 - loss: 0.54692
iteration: 19450 - loss: 0.52566
iteration: 19500 - loss: 0.52070
iteration: 19550 - loss: 0.51352
iteration: 19600 - loss: 0.51212
iteration: 19650 - loss: 0.53878
iteration: 19700 - loss: 0.51100
iteration: 19750 - loss: 0.51545
iteration: 19800 - loss: 0.50664
iteration: 19850 - loss: 0.54796
iteration: 19900 - loss: 0.50313
iteration: 19950 - loss: 0.50049
iteration: 20000 - loss: 0.53895
iteration: 20050 - loss: 0.53336
iteration: 20100 - loss: 0.51023
iteration: 20150 - loss: 0.51323
iteration: 20200 - loss: 0.53730
iteration: 20250 - loss: 0.50444
iteration: 20300 - loss: 0.53027
iteration: 20350 - loss: 0.52625
iteration: 20400 - loss: 0.55480
iteration: 20450 - loss: 0.48808
iteration: 20500 - loss: 0.48346
iteration: 20550 - loss: 0.46941
iteration: 20600 - loss: 0.52622
iteration: 20650 - loss: 0.53233
iteration: 20700 - loss: 0.57140
iteration: 20750 - loss: 0.49648
iteration: 20800 - loss: 0.51787
iteration: 20850 - loss: 0.47669
iteration: 20900 - loss: 0.53481
iteration: 20950 - loss: 0.54884
iteration: 21000 - loss: 0.51318
iteration: 21050 - loss: 0.48678
iteration: 21100 - loss: 0.54205
iteration: 21150 - loss: 0.54663
iteration: 21200 - loss: 0.50068
iteration: 21250 - loss: 0.51692
iteration: 21300 - loss: 0.46453
iteration: 21350 - loss: 0.54527
iteration: 21400 - loss: 0.52027
iteration: 21450 - loss: 0.50724
iteration: 21500 - loss: 0.55485
iteration: 21550 - loss: 0.53835
iteration: 21600 - loss: 0.48359
iteration: 21650 - loss: 0.56367
iteration: 21700 - loss: 0.49391
iteration: 21750 - loss: 0.51426
iteration: 21800 - loss: 0.51107
iteration: 21850 - loss: 0.53699
iteration: 21900 - loss: 0.50113
iteration: 21950 - loss: 0.51162
iteration: 22000 - loss: 0.53092
iteration: 22050 - loss: 0.54060
iteration: 22100 - loss: 0.50105
iteration: 22150 - loss: 0.52219
iteration: 22200 - loss: 0.51136
iteration: 22250 - loss: 0.51181
iteration: 22300 - loss: 0.49981
iteration: 22350 - loss: 0.50465
iteration: 22400 - loss: 0.53060
iteration: 22450 - loss: 0.53760
iteration: 22500 - loss: 0.52870
iteration: 22550 - loss: 0.49063
iteration: 22600 - loss: 0.50477
iteration: 22650 - loss: 0.52608
iteration: 22700 - loss: 0.51980
iteration: 22750 - loss: 0.54891
iteration: 22800 - loss: 0.49664
iteration: 22850 - loss: 0.49250
iteration: 22900 - loss: 0.53995
iteration: 22950 - loss: 0.51937
iteration: 23000 - loss: 0.53826
iteration: 23050 - loss: 0.51508
iteration: 23100 - loss: 0.49360
iteration: 23150 - loss: 0.49900
iteration: 23200 - loss: 0.53969
iteration: 23250 - loss: 0.55159
iteration: 23300 - loss: 0.50484
iteration: 23350 - loss: 0.53389
iteration: 23400 - loss: 0.47906
iteration: 23450 - loss: 0.53550
iteration: 23500 - loss: 0.53806
iteration: 23550 - loss: 0.46528
iteration: 23600 - loss: 0.52029
iteration: 23650 - loss: 0.53594
iteration: 23700 - loss: 0.52691
iteration: 23750 - loss: 0.54009
iteration: 23800 - loss: 0.53365
iteration: 23850 - loss: 0.53651
iteration: 23900 - loss: 0.48230
iteration: 23950 - loss: 0.54406
iteration: 24000 - loss: 0.49292
iteration: 24050 - loss: 0.51633
iteration: 24100 - loss: 0.52988
iteration: 24150 - loss: 0.50039
iteration: 24200 - loss: 0.51593
iteration: 24250 - loss: 0.53048
iteration: 24300 - loss: 0.50089
iteration: 24350 - loss: 0.49946
iteration: 24400 - loss: 0.57277
iteration: 24450 - loss: 0.50989
iteration: 24500 - loss: 0.51947
iteration: 24550 - loss: 0.49105
iteration: 24600 - loss: 0.51922
iteration: 24650 - loss: 0.56177
iteration: 24700 - loss: 0.48400
iteration: 24750 - loss: 0.53661
iteration: 24800 - loss: 0.50717
iteration: 24850 - loss: 0.49845
iteration: 24900 - loss: 0.50076
iteration: 24950 - loss: 0.54966
rmse: 1.0372
dcg: 10.3878
Reading dataset
Dataset read complete...
n users: 75
n items: 3287
Model intialized
Beginning Training...
cuda
mse loss
Training on GPU: 1 devices
iteration: 0 - loss: 14.91833
iteration: 50 - loss: 13.69075
iteration: 100 - loss: 13.64501
iteration: 150 - loss: 13.80121
iteration: 200 - loss: 13.53164
iteration: 250 - loss: 13.38863
iteration: 300 - loss: 12.87912
iteration: 350 - loss: 12.61191
iteration: 400 - loss: 11.28320
iteration: 450 - loss: 9.98486
iteration: 500 - loss: 8.15895
iteration: 550 - loss: 6.02905
iteration: 600 - loss: 4.00757
iteration: 650 - loss: 2.57980
iteration: 700 - loss: 1.53010
iteration: 750 - loss: 1.08836
iteration: 800 - loss: 0.97053
iteration: 850 - loss: 0.91773
iteration: 900 - loss: 0.89304
iteration: 950 - loss: 0.91556
iteration: 1000 - loss: 0.91982
iteration: 1050 - loss: 0.89929
iteration: 1100 - loss: 0.81720
iteration: 1150 - loss: 0.89931
iteration: 1200 - loss: 0.86380
iteration: 1250 - loss: 0.91332
iteration: 1300 - loss: 0.86747
iteration: 1350 - loss: 0.82215
iteration: 1400 - loss: 0.84124
iteration: 1450 - loss: 0.84947
iteration: 1500 - loss: 0.85692
iteration: 1550 - loss: 0.81925
iteration: 1600 - loss: 0.78845
iteration: 1650 - loss: 0.84247
iteration: 1700 - loss: 0.77310
iteration: 1750 - loss: 0.83943
iteration: 1800 - loss: 0.80247
iteration: 1850 - loss: 0.78927
iteration: 1900 - loss: 0.77442
iteration: 1950 - loss: 0.75433
iteration: 2000 - loss: 0.81879
iteration: 2050 - loss: 0.77502
iteration: 2100 - loss: 0.78854
iteration: 2150 - loss: 0.76771
iteration: 2200 - loss: 0.79500
iteration: 2250 - loss: 0.70470
iteration: 2300 - loss: 0.71977
iteration: 2350 - loss: 0.75675
iteration: 2400 - loss: 0.75919
iteration: 2450 - loss: 0.73872
iteration: 2500 - loss: 0.72997
iteration: 2550 - loss: 0.71752
iteration: 2600 - loss: 0.76060
iteration: 2650 - loss: 0.69190
iteration: 2700 - loss: 0.70849
iteration: 2750 - loss: 0.73532
iteration: 2800 - loss: 0.67166
iteration: 2850 - loss: 0.72575
iteration: 2900 - loss: 0.74961
iteration: 2950 - loss: 0.67093
iteration: 3000 - loss: 0.68550
iteration: 3050 - loss: 0.72464
iteration: 3100 - loss: 0.63603
iteration: 3150 - loss: 0.65557
iteration: 3200 - loss: 0.70056
iteration: 3250 - loss: 0.70715
iteration: 3300 - loss: 0.65940
iteration: 3350 - loss: 0.65948
iteration: 3400 - loss: 0.67395
iteration: 3450 - loss: 0.64139
iteration: 3500 - loss: 0.70941
iteration: 3550 - loss: 0.66328
iteration: 3600 - loss: 0.65537
iteration: 3650 - loss: 0.64432
iteration: 3700 - loss: 0.64301
iteration: 3750 - loss: 0.65055
iteration: 3800 - loss: 0.66031
iteration: 3850 - loss: 0.63112
iteration: 3900 - loss: 0.64209
iteration: 3950 - loss: 0.63668
iteration: 4000 - loss: 0.63102
iteration: 4050 - loss: 0.63668
iteration: 4100 - loss: 0.61367
iteration: 4150 - loss: 0.61218
iteration: 4200 - loss: 0.63712
iteration: 4250 - loss: 0.62123
iteration: 4300 - loss: 0.65027
iteration: 4350 - loss: 0.58880
iteration: 4400 - loss: 0.58930
iteration: 4450 - loss: 0.59569
iteration: 4500 - loss: 0.63393
iteration: 4550 - loss: 0.58503
iteration: 4600 - loss: 0.60067
iteration: 4650 - loss: 0.59950
iteration: 4700 - loss: 0.60081
iteration: 4750 - loss: 0.62129
iteration: 4800 - loss: 0.57633
iteration: 4850 - loss: 0.60097
iteration: 4900 - loss: 0.64288
iteration: 4950 - loss: 0.59437
iteration: 5000 - loss: 0.54897
iteration: 5050 - loss: 0.62146
iteration: 5100 - loss: 0.57477
iteration: 5150 - loss: 0.54869
iteration: 5200 - loss: 0.57980
iteration: 5250 - loss: 0.58626
iteration: 5300 - loss: 0.56695
iteration: 5350 - loss: 0.56996
iteration: 5400 - loss: 0.56865
iteration: 5450 - loss: 0.58852
iteration: 5500 - loss: 0.58086
iteration: 5550 - loss: 0.52623
iteration: 5600 - loss: 0.55763
iteration: 5650 - loss: 0.60077
iteration: 5700 - loss: 0.55928
iteration: 5750 - loss: 0.59655
iteration: 5800 - loss: 0.54752
iteration: 5850 - loss: 0.56726
iteration: 5900 - loss: 0.54250
iteration: 5950 - loss: 0.54962
iteration: 6000 - loss: 0.60757
iteration: 6050 - loss: 0.54102
iteration: 6100 - loss: 0.52702
iteration: 6150 - loss: 0.59412
iteration: 6200 - loss: 0.53754
iteration: 6250 - loss: 0.57727
iteration: 6300 - loss: 0.56887
iteration: 6350 - loss: 0.57061
iteration: 6400 - loss: 0.57187
iteration: 6450 - loss: 0.51585
iteration: 6500 - loss: 0.53280
iteration: 6550 - loss: 0.49626
iteration: 6600 - loss: 0.56965
iteration: 6650 - loss: 0.56871
iteration: 6700 - loss: 0.53483
iteration: 6750 - loss: 0.57556
iteration: 6800 - loss: 0.54860
iteration: 6850 - loss: 0.56680
iteration: 6900 - loss: 0.50020
iteration: 6950 - loss: 0.58733
iteration: 7000 - loss: 0.50985
iteration: 7050 - loss: 0.52643
iteration: 7100 - loss: 0.55830
iteration: 7150 - loss: 0.52757
iteration: 7200 - loss: 0.55158
iteration: 7250 - loss: 0.54779
iteration: 7300 - loss: 0.52933
iteration: 7350 - loss: 0.56187
iteration: 7400 - loss: 0.52624
iteration: 7450 - loss: 0.51582
iteration: 7500 - loss: 0.54653
iteration: 7550 - loss: 0.50351
iteration: 7600 - loss: 0.52507
iteration: 7650 - loss: 0.54014
iteration: 7700 - loss: 0.59557
iteration: 7750 - loss: 0.51755
iteration: 7800 - loss: 0.50163
iteration: 7850 - loss: 0.59171
iteration: 7900 - loss: 0.50872
iteration: 7950 - loss: 0.51415
iteration: 8000 - loss: 0.55290
iteration: 8050 - loss: 0.50034
iteration: 8100 - loss: 0.54094
iteration: 8150 - loss: 0.50173
iteration: 8200 - loss: 0.54741
iteration: 8250 - loss: 0.56951
iteration: 8300 - loss: 0.54260
iteration: 8350 - loss: 0.53422
iteration: 8400 - loss: 0.52867
iteration: 8450 - loss: 0.54743
iteration: 8500 - loss: 0.49742
iteration: 8550 - loss: 0.49669
iteration: 8600 - loss: 0.54568
iteration: 8650 - loss: 0.53489
iteration: 8700 - loss: 0.53070
iteration: 8750 - loss: 0.53467
iteration: 8800 - loss: 0.51673
iteration: 8850 - loss: 0.52867
iteration: 8900 - loss: 0.52844
iteration: 8950 - loss: 0.54326
iteration: 9000 - loss: 0.52054
iteration: 9050 - loss: 0.53860
iteration: 9100 - loss: 0.51664
iteration: 9150 - loss: 0.51085
iteration: 9200 - loss: 0.53447
iteration: 9250 - loss: 0.53319
iteration: 9300 - loss: 0.54905
iteration: 9350 - loss: 0.54670
iteration: 9400 - loss: 0.53602
iteration: 9450 - loss: 0.48358
iteration: 9500 - loss: 0.51613
iteration: 9550 - loss: 0.53113
iteration: 9600 - loss: 0.50518
iteration: 9650 - loss: 0.51010
iteration: 9700 - loss: 0.54151
iteration: 9750 - loss: 0.53563
iteration: 9800 - loss: 0.44508
iteration: 9850 - loss: 0.50364
iteration: 9900 - loss: 0.55606
iteration: 9950 - loss: 0.53545
iteration: 10000 - loss: 0.57873
iteration: 10050 - loss: 0.53663
iteration: 10100 - loss: 0.49537
iteration: 10150 - loss: 0.51224
iteration: 10200 - loss: 0.52717
iteration: 10250 - loss: 0.53559
iteration: 10300 - loss: 0.49117
iteration: 10350 - loss: 0.54468
iteration: 10400 - loss: 0.55924
iteration: 10450 - loss: 0.48481
iteration: 10500 - loss: 0.53299
iteration: 10550 - loss: 0.54064
iteration: 10600 - loss: 0.51266
iteration: 10650 - loss: 0.55032
iteration: 10700 - loss: 0.49636
iteration: 10750 - loss: 0.51421
iteration: 10800 - loss: 0.53187
iteration: 10850 - loss: 0.49860
iteration: 10900 - loss: 0.56237
iteration: 10950 - loss: 0.49128
iteration: 11000 - loss: 0.52725
iteration: 11050 - loss: 0.49805
iteration: 11100 - loss: 0.49698
iteration: 11150 - loss: 0.53753
iteration: 11200 - loss: 0.54187
iteration: 11250 - loss: 0.52902
iteration: 11300 - loss: 0.53242
iteration: 11350 - loss: 0.47971
iteration: 11400 - loss: 0.54087
iteration: 11450 - loss: 0.53031
iteration: 11500 - loss: 0.53024
iteration: 11550 - loss: 0.50421
iteration: 11600 - loss: 0.48486
iteration: 11650 - loss: 0.58379
iteration: 11700 - loss: 0.53728
iteration: 11750 - loss: 0.48234
iteration: 11800 - loss: 0.50503
iteration: 11850 - loss: 0.49111
iteration: 11900 - loss: 0.55455
iteration: 11950 - loss: 0.51652
iteration: 12000 - loss: 0.54070
iteration: 12050 - loss: 0.52275
iteration: 12100 - loss: 0.51647
iteration: 12150 - loss: 0.53367
iteration: 12200 - loss: 0.47754
iteration: 12250 - loss: 0.54630
iteration: 12300 - loss: 0.49611
iteration: 12350 - loss: 0.51100
iteration: 12400 - loss: 0.52493
iteration: 12450 - loss: 0.53849
iteration: 12500 - loss: 0.54663
iteration: 12550 - loss: 0.50058
iteration: 12600 - loss: 0.54354
iteration: 12650 - loss: 0.49200
iteration: 12700 - loss: 0.52680
iteration: 12750 - loss: 0.52774
iteration: 12800 - loss: 0.52016
iteration: 12850 - loss: 0.52741
iteration: 12900 - loss: 0.50965
iteration: 12950 - loss: 0.51614
iteration: 13000 - loss: 0.53596
iteration: 13050 - loss: 0.52663
iteration: 13100 - loss: 0.53761
iteration: 13150 - loss: 0.50411
iteration: 13200 - loss: 0.51466
iteration: 13250 - loss: 0.51120
iteration: 13300 - loss: 0.52162
iteration: 13350 - loss: 0.54624
iteration: 13400 - loss: 0.52405
iteration: 13450 - loss: 0.51403
iteration: 13500 - loss: 0.49393
iteration: 13550 - loss: 0.49992
iteration: 13600 - loss: 0.54641
iteration: 13650 - loss: 0.53566
iteration: 13700 - loss: 0.48767
iteration: 13750 - loss: 0.53164
iteration: 13800 - loss: 0.47800
iteration: 13850 - loss: 0.53030
iteration: 13900 - loss: 0.52686
iteration: 13950 - loss: 0.54037
iteration: 14000 - loss: 0.51933
iteration: 14050 - loss: 0.51621
iteration: 14100 - loss: 0.52582
iteration: 14150 - loss: 0.48895
iteration: 14200 - loss: 0.55548
iteration: 14250 - loss: 0.51452
iteration: 14300 - loss: 0.49636
iteration: 14350 - loss: 0.51835
iteration: 14400 - loss: 0.50459
iteration: 14450 - loss: 0.56221
iteration: 14500 - loss: 0.51693
iteration: 14550 - loss: 0.50976
iteration: 14600 - loss: 0.48635
iteration: 14650 - loss: 0.50461
iteration: 14700 - loss: 0.55789
iteration: 14750 - loss: 0.53761
iteration: 14800 - loss: 0.48428
iteration: 14850 - loss: 0.57178
iteration: 14900 - loss: 0.47675
iteration: 14950 - loss: 0.55237
iteration: 15000 - loss: 0.52021
iteration: 15050 - loss: 0.50365
iteration: 15100 - loss: 0.47762
iteration: 15150 - loss: 0.51246
iteration: 15200 - loss: 0.54016
iteration: 15250 - loss: 0.55354
iteration: 15300 - loss: 0.49311
iteration: 15350 - loss: 0.49077
iteration: 15400 - loss: 0.54470
iteration: 15450 - loss: 0.50534
iteration: 15500 - loss: 0.56872
iteration: 15550 - loss: 0.49187
iteration: 15600 - loss: 0.46451
iteration: 15650 - loss: 0.54343
iteration: 15700 - loss: 0.56791
iteration: 15750 - loss: 0.52446
iteration: 15800 - loss: 0.50106
iteration: 15850 - loss: 0.53556
iteration: 15900 - loss: 0.50511
iteration: 15950 - loss: 0.52063
iteration: 16000 - loss: 0.53468
iteration: 16050 - loss: 0.49843
iteration: 16100 - loss: 0.50290
iteration: 16150 - loss: 0.48051
iteration: 16200 - loss: 0.50894
iteration: 16250 - loss: 0.60529
iteration: 16300 - loss: 0.51039
iteration: 16350 - loss: 0.52508
iteration: 16400 - loss: 0.50031
iteration: 16450 - loss: 0.51914
iteration: 16500 - loss: 0.55076
iteration: 16550 - loss: 0.54591
iteration: 16600 - loss: 0.51785
iteration: 16650 - loss: 0.51447
iteration: 16700 - loss: 0.52397
iteration: 16750 - loss: 0.50437
iteration: 16800 - loss: 0.54719
iteration: 16850 - loss: 0.49236
iteration: 16900 - loss: 0.51436
iteration: 16950 - loss: 0.50844
iteration: 17000 - loss: 0.52181
iteration: 17050 - loss: 0.51878
iteration: 17100 - loss: 0.51859
iteration: 17150 - loss: 0.54271
iteration: 17200 - loss: 0.50759
iteration: 17250 - loss: 0.51358
iteration: 17300 - loss: 0.51045
iteration: 17350 - loss: 0.47798
iteration: 17400 - loss: 0.53301
iteration: 17450 - loss: 0.53312
iteration: 17500 - loss: 0.54295
iteration: 17550 - loss: 0.52519
iteration: 17600 - loss: 0.50372
iteration: 17650 - loss: 0.51679
iteration: 17700 - loss: 0.53165
iteration: 17750 - loss: 0.52106
iteration: 17800 - loss: 0.52211
iteration: 17850 - loss: 0.49123
iteration: 17900 - loss: 0.53231
iteration: 17950 - loss: 0.55282
iteration: 18000 - loss: 0.49640
iteration: 18050 - loss: 0.49338
iteration: 18100 - loss: 0.53066
iteration: 18150 - loss: 0.51254
iteration: 18200 - loss: 0.54600
iteration: 18250 - loss: 0.52080
iteration: 18300 - loss: 0.50658
iteration: 18350 - loss: 0.54907
iteration: 18400 - loss: 0.51329
iteration: 18450 - loss: 0.50076
iteration: 18500 - loss: 0.52871
iteration: 18550 - loss: 0.56501
iteration: 18600 - loss: 0.52759
iteration: 18650 - loss: 0.48776
iteration: 18700 - loss: 0.48794
iteration: 18750 - loss: 0.52069
iteration: 18800 - loss: 0.49229
iteration: 18850 - loss: 0.53256
iteration: 18900 - loss: 0.51457
iteration: 18950 - loss: 0.50983
iteration: 19000 - loss: 0.54765
iteration: 19050 - loss: 0.52374
iteration: 19100 - loss: 0.51255
iteration: 19150 - loss: 0.50397
iteration: 19200 - loss: 0.52183
iteration: 19250 - loss: 0.53496
iteration: 19300 - loss: 0.52600
iteration: 19350 - loss: 0.51883
iteration: 19400 - loss: 0.46945
iteration: 19450 - loss: 0.52183
iteration: 19500 - loss: 0.55342
iteration: 19550 - loss: 0.50380
iteration: 19600 - loss: 0.50234
iteration: 19650 - loss: 0.52794
iteration: 19700 - loss: 0.47979
iteration: 19750 - loss: 0.58831
iteration: 19800 - loss: 0.48315
iteration: 19850 - loss: 0.49946
iteration: 19900 - loss: 0.50425
iteration: 19950 - loss: 0.52949
iteration: 20000 - loss: 0.57406
iteration: 20050 - loss: 0.50483
iteration: 20100 - loss: 0.53666
iteration: 20150 - loss: 0.51418
iteration: 20200 - loss: 0.51589
iteration: 20250 - loss: 0.52970
iteration: 20300 - loss: 0.48183
iteration: 20350 - loss: 0.52972
iteration: 20400 - loss: 0.50596
iteration: 20450 - loss: 0.55022
iteration: 20500 - loss: 0.52797
iteration: 20550 - loss: 0.50440
iteration: 20600 - loss: 0.49195
iteration: 20650 - loss: 0.55046
iteration: 20700 - loss: 0.49365
iteration: 20750 - loss: 0.54972
iteration: 20800 - loss: 0.50744
iteration: 20850 - loss: 0.53558
iteration: 20900 - loss: 0.50537
iteration: 20950 - loss: 0.52140
iteration: 21000 - loss: 0.52796
iteration: 21050 - loss: 0.55311
iteration: 21100 - loss: 0.51489
iteration: 21150 - loss: 0.51202
iteration: 21200 - loss: 0.49728
iteration: 21250 - loss: 0.52110
iteration: 21300 - loss: 0.54319
iteration: 21350 - loss: 0.51089
iteration: 21400 - loss: 0.50340
iteration: 21450 - loss: 0.51664
iteration: 21500 - loss: 0.52124
iteration: 21550 - loss: 0.51859
iteration: 21600 - loss: 0.48182
iteration: 21650 - loss: 0.54234
iteration: 21700 - loss: 0.53509
iteration: 21750 - loss: 0.51262
iteration: 21800 - loss: 0.49615
iteration: 21850 - loss: 0.53057
iteration: 21900 - loss: 0.51370
iteration: 21950 - loss: 0.53162
iteration: 22000 - loss: 0.52271
iteration: 22050 - loss: 0.51425
iteration: 22100 - loss: 0.49686
iteration: 22150 - loss: 0.50737
iteration: 22200 - loss: 0.55482
iteration: 22250 - loss: 0.52773
iteration: 22300 - loss: 0.50734
iteration: 22350 - loss: 0.48607
iteration: 22400 - loss: 0.51427
iteration: 22450 - loss: 0.56663
iteration: 22500 - loss: 0.52224
iteration: 22550 - loss: 0.53456
iteration: 22600 - loss: 0.48478
iteration: 22650 - loss: 0.52485
iteration: 22700 - loss: 0.49405
iteration: 22750 - loss: 0.55196
iteration: 22800 - loss: 0.51079
iteration: 22850 - loss: 0.51227
iteration: 22900 - loss: 0.51009
iteration: 22950 - loss: 0.54083
iteration: 23000 - loss: 0.52078
iteration: 23050 - loss: 0.49873
iteration: 23100 - loss: 0.55169
iteration: 23150 - loss: 0.50853
iteration: 23200 - loss: 0.51639
iteration: 23250 - loss: 0.51491
iteration: 23300 - loss: 0.48542
iteration: 23350 - loss: 0.50485
iteration: 23400 - loss: 0.54903
iteration: 23450 - loss: 0.54282
iteration: 23500 - loss: 0.51553
iteration: 23550 - loss: 0.46095
iteration: 23600 - loss: 0.51563
iteration: 23650 - loss: 0.53361
iteration: 23700 - loss: 0.55533
iteration: 23750 - loss: 0.53107
iteration: 23800 - loss: 0.49691
iteration: 23850 - loss: 0.52882
iteration: 23900 - loss: 0.49457
iteration: 23950 - loss: 0.53793
iteration: 24000 - loss: 0.54387
iteration: 24050 - loss: 0.52767
iteration: 24100 - loss: 0.53250
iteration: 24150 - loss: 0.48761
iteration: 24200 - loss: 0.49383
iteration: 24250 - loss: 0.54738
iteration: 24300 - loss: 0.50056
iteration: 24350 - loss: 0.53082
iteration: 24400 - loss: 0.52004
iteration: 24450 - loss: 0.51871
iteration: 24500 - loss: 0.52438
iteration: 24550 - loss: 0.52900
iteration: 24600 - loss: 0.53300
iteration: 24650 - loss: 0.50343
iteration: 24700 - loss: 0.51602
iteration: 24750 - loss: 0.51435
iteration: 24800 - loss: 0.49787
iteration: 24850 - loss: 0.52723
iteration: 24900 - loss: 0.50894
iteration: 24950 - loss: 0.51829
rmse: 1.0366
dcg: 10.4556
Reading dataset
Dataset read complete...
n users: 75
n items: 3287
Model intialized
Beginning Training...
cuda
mse loss
Training on GPU: 1 devices
iteration: 0 - loss: 12.86054
iteration: 50 - loss: 14.44315
iteration: 100 - loss: 13.74797
iteration: 150 - loss: 13.67229
iteration: 200 - loss: 13.90052
iteration: 250 - loss: 13.89530
iteration: 300 - loss: 13.31511
iteration: 350 - loss: 13.05890
iteration: 400 - loss: 12.10351
iteration: 450 - loss: 11.00550
iteration: 500 - loss: 9.18041
iteration: 550 - loss: 7.19413
iteration: 600 - loss: 5.11956
iteration: 650 - loss: 3.18232
iteration: 700 - loss: 1.74296
iteration: 750 - loss: 1.13309
iteration: 800 - loss: 1.00914
iteration: 850 - loss: 0.92460
iteration: 900 - loss: 0.89934
iteration: 950 - loss: 0.88631
iteration: 1000 - loss: 0.94776
iteration: 1050 - loss: 0.88758
iteration: 1100 - loss: 0.88126
iteration: 1150 - loss: 0.90609
iteration: 1200 - loss: 0.87858
iteration: 1250 - loss: 0.85910
iteration: 1300 - loss: 0.81543
iteration: 1350 - loss: 0.86738
iteration: 1400 - loss: 0.85986
iteration: 1450 - loss: 0.85023
iteration: 1500 - loss: 0.84439
iteration: 1550 - loss: 0.80497
iteration: 1600 - loss: 0.84741
iteration: 1650 - loss: 0.88399
iteration: 1700 - loss: 0.81043
iteration: 1750 - loss: 0.75437
iteration: 1800 - loss: 0.80636
iteration: 1850 - loss: 0.80956
iteration: 1900 - loss: 0.76688
iteration: 1950 - loss: 0.74792
iteration: 2000 - loss: 0.83791
iteration: 2050 - loss: 0.75806
iteration: 2100 - loss: 0.77165
iteration: 2150 - loss: 0.82548
iteration: 2200 - loss: 0.71716
iteration: 2250 - loss: 0.77848
iteration: 2300 - loss: 0.75189
iteration: 2350 - loss: 0.74356
iteration: 2400 - loss: 0.76071
iteration: 2450 - loss: 0.76571
iteration: 2500 - loss: 0.71445
iteration: 2550 - loss: 0.78671
iteration: 2600 - loss: 0.69784
iteration: 2650 - loss: 0.73703
iteration: 2700 - loss: 0.72339
iteration: 2750 - loss: 0.68719
iteration: 2800 - loss: 0.70047
iteration: 2850 - loss: 0.67029
iteration: 2900 - loss: 0.68198
iteration: 2950 - loss: 0.73780
iteration: 3000 - loss: 0.74963
iteration: 3050 - loss: 0.66411
iteration: 3100 - loss: 0.65823
iteration: 3150 - loss: 0.72666
iteration: 3200 - loss: 0.72066
iteration: 3250 - loss: 0.67976
iteration: 3300 - loss: 0.67469
iteration: 3350 - loss: 0.67569
iteration: 3400 - loss: 0.66159
iteration: 3450 - loss: 0.68952
iteration: 3500 - loss: 0.66533
iteration: 3550 - loss: 0.63189
iteration: 3600 - loss: 0.64066
iteration: 3650 - loss: 0.63834
iteration: 3700 - loss: 0.72453
iteration: 3750 - loss: 0.65554
iteration: 3800 - loss: 0.70057
iteration: 3850 - loss: 0.64519
iteration: 3900 - loss: 0.64012
iteration: 3950 - loss: 0.65844
iteration: 4000 - loss: 0.56695
iteration: 4050 - loss: 0.58824
iteration: 4100 - loss: 0.64560
iteration: 4150 - loss: 0.65622
iteration: 4200 - loss: 0.65670
iteration: 4250 - loss: 0.60867
iteration: 4300 - loss: 0.63415
iteration: 4350 - loss: 0.63369
iteration: 4400 - loss: 0.59693
iteration: 4450 - loss: 0.64988
iteration: 4500 - loss: 0.57016
iteration: 4550 - loss: 0.60610
iteration: 4600 - loss: 0.65998
iteration: 4650 - loss: 0.61132
iteration: 4700 - loss: 0.58004
iteration: 4750 - loss: 0.57282
iteration: 4800 - loss: 0.60300
iteration: 4850 - loss: 0.57941
iteration: 4900 - loss: 0.59139
iteration: 4950 - loss: 0.58114
iteration: 5000 - loss: 0.62893
iteration: 5050 - loss: 0.57224
iteration: 5100 - loss: 0.59448
iteration: 5150 - loss: 0.61388
iteration: 5200 - loss: 0.58665
iteration: 5250 - loss: 0.57692
iteration: 5300 - loss: 0.55340
iteration: 5350 - loss: 0.57439
iteration: 5400 - loss: 0.58176
iteration: 5450 - loss: 0.60297
iteration: 5500 - loss: 0.57752
iteration: 5550 - loss: 0.53539
iteration: 5600 - loss: 0.54075
iteration: 5650 - loss: 0.55010
iteration: 5700 - loss: 0.61013
iteration: 5750 - loss: 0.62119
iteration: 5800 - loss: 0.54869
iteration: 5850 - loss: 0.58134
iteration: 5900 - loss: 0.56792
iteration: 5950 - loss: 0.59180
iteration: 6000 - loss: 0.53870
iteration: 6050 - loss: 0.55987
iteration: 6100 - loss: 0.53653
iteration: 6150 - loss: 0.57246
iteration: 6200 - loss: 0.59226
iteration: 6250 - loss: 0.53272
iteration: 6300 - loss: 0.55263
iteration: 6350 - loss: 0.59300
iteration: 6400 - loss: 0.53557
iteration: 6450 - loss: 0.58734
iteration: 6500 - loss: 0.50547
iteration: 6550 - loss: 0.57786
iteration: 6600 - loss: 0.52965
iteration: 6650 - loss: 0.54749
iteration: 6700 - loss: 0.54277
iteration: 6750 - loss: 0.55338
iteration: 6800 - loss: 0.51894
iteration: 6850 - loss: 0.52799
iteration: 6900 - loss: 0.55520
iteration: 6950 - loss: 0.57672
iteration: 7000 - loss: 0.56092
iteration: 7050 - loss: 0.54165
iteration: 7100 - loss: 0.53233
iteration: 7150 - loss: 0.55932
iteration: 7200 - loss: 0.55371
iteration: 7250 - loss: 0.51589
iteration: 7300 - loss: 0.55853
iteration: 7350 - loss: 0.52100
iteration: 7400 - loss: 0.50027
iteration: 7450 - loss: 0.57320
iteration: 7500 - loss: 0.54774
iteration: 7550 - loss: 0.53394
iteration: 7600 - loss: 0.54450
iteration: 7650 - loss: 0.55003
iteration: 7700 - loss: 0.55166
iteration: 7750 - loss: 0.50667
iteration: 7800 - loss: 0.52228
iteration: 7850 - loss: 0.52931
iteration: 7900 - loss: 0.50814
iteration: 7950 - loss: 0.55365
iteration: 8000 - loss: 0.56125
iteration: 8050 - loss: 0.50354
iteration: 8100 - loss: 0.51435
iteration: 8150 - loss: 0.51653
iteration: 8200 - loss: 0.55316
iteration: 8250 - loss: 0.57731
iteration: 8300 - loss: 0.47406
iteration: 8350 - loss: 0.54560
iteration: 8400 - loss: 0.52596
iteration: 8450 - loss: 0.49042
iteration: 8500 - loss: 0.62153
iteration: 8550 - loss: 0.52568
iteration: 8600 - loss: 0.52627
iteration: 8650 - loss: 0.49104
iteration: 8700 - loss: 0.52970
iteration: 8750 - loss: 0.57769
iteration: 8800 - loss: 0.49236
iteration: 8850 - loss: 0.49720
iteration: 8900 - loss: 0.55089
iteration: 8950 - loss: 0.52424
iteration: 9000 - loss: 0.57325
iteration: 9050 - loss: 0.56725
iteration: 9100 - loss: 0.50925
iteration: 9150 - loss: 0.50692
iteration: 9200 - loss: 0.53701
iteration: 9250 - loss: 0.51798
iteration: 9300 - loss: 0.49669
iteration: 9350 - loss: 0.54117
iteration: 9400 - loss: 0.53726
iteration: 9450 - loss: 0.52507
iteration: 9500 - loss: 0.53199
iteration: 9550 - loss: 0.52950
iteration: 9600 - loss: 0.51220
iteration: 9650 - loss: 0.54672
iteration: 9700 - loss: 0.51337
iteration: 9750 - loss: 0.52212
iteration: 9800 - loss: 0.52642
iteration: 9850 - loss: 0.52011
iteration: 9900 - loss: 0.53611
iteration: 9950 - loss: 0.52052
iteration: 10000 - loss: 0.51963
iteration: 10050 - loss: 0.52789
iteration: 10100 - loss: 0.50746
iteration: 10150 - loss: 0.49068
iteration: 10200 - loss: 0.52208
iteration: 10250 - loss: 0.57249
iteration: 10300 - loss: 0.50317
iteration: 10350 - loss: 0.56253
iteration: 10400 - loss: 0.50800
iteration: 10450 - loss: 0.50023
iteration: 10500 - loss: 0.53739
iteration: 10550 - loss: 0.54846
iteration: 10600 - loss: 0.47110
iteration: 10650 - loss: 0.56372
iteration: 10700 - loss: 0.50568
iteration: 10750 - loss: 0.51921
iteration: 10800 - loss: 0.48839
iteration: 10850 - loss: 0.54249
iteration: 10900 - loss: 0.52994
iteration: 10950 - loss: 0.52758
iteration: 11000 - loss: 0.52409
iteration: 11050 - loss: 0.55306
iteration: 11100 - loss: 0.50269
iteration: 11150 - loss: 0.52569
iteration: 11200 - loss: 0.53606
iteration: 11250 - loss: 0.49055
iteration: 11300 - loss: 0.50709
iteration: 11350 - loss: 0.53052
iteration: 11400 - loss: 0.52476
iteration: 11450 - loss: 0.49029
iteration: 11500 - loss: 0.56268
iteration: 11550 - loss: 0.48244
iteration: 11600 - loss: 0.54244
iteration: 11650 - loss: 0.48014
iteration: 11700 - loss: 0.56345
iteration: 11750 - loss: 0.53788
iteration: 11800 - loss: 0.50235
iteration: 11850 - loss: 0.52729
iteration: 11900 - loss: 0.47692
iteration: 11950 - loss: 0.52407
iteration: 12000 - loss: 0.56741
iteration: 12050 - loss: 0.49372
iteration: 12100 - loss: 0.53886
iteration: 12150 - loss: 0.49038
iteration: 12200 - loss: 0.51414
iteration: 12250 - loss: 0.56347
iteration: 12300 - loss: 0.51415
iteration: 12350 - loss: 0.49333
iteration: 12400 - loss: 0.51792
iteration: 12450 - loss: 0.51757
iteration: 12500 - loss: 0.55781
iteration: 12550 - loss: 0.50997
iteration: 12600 - loss: 0.53728
iteration: 12650 - loss: 0.51380
iteration: 12700 - loss: 0.51284
iteration: 12750 - loss: 0.53566
iteration: 12800 - loss: 0.48761
iteration: 12850 - loss: 0.49911
iteration: 12900 - loss: 0.53481
iteration: 12950 - loss: 0.52615
iteration: 13000 - loss: 0.54623
iteration: 13050 - loss: 0.48160
iteration: 13100 - loss: 0.53213
iteration: 13150 - loss: 0.52235
iteration: 13200 - loss: 0.55984
iteration: 13250 - loss: 0.49720
iteration: 13300 - loss: 0.53513
iteration: 13350 - loss: 0.50499
iteration: 13400 - loss: 0.50019
iteration: 13450 - loss: 0.54149
iteration: 13500 - loss: 0.52465
iteration: 13550 - loss: 0.50980
iteration: 13600 - loss: 0.51002
iteration: 13650 - loss: 0.49144
iteration: 13700 - loss: 0.55070
iteration: 13750 - loss: 0.53154
iteration: 13800 - loss: 0.52812
iteration: 13850 - loss: 0.52696
iteration: 13900 - loss: 0.49079
iteration: 13950 - loss: 0.52566
iteration: 14000 - loss: 0.52705
iteration: 14050 - loss: 0.46983
iteration: 14100 - loss: 0.50934
iteration: 14150 - loss: 0.54954
iteration: 14200 - loss: 0.51428
iteration: 14250 - loss: 0.55539
iteration: 14300 - loss: 0.49769
iteration: 14350 - loss: 0.51902
iteration: 14400 - loss: 0.55444
iteration: 14450 - loss: 0.49464
iteration: 14500 - loss: 0.53190
iteration: 14550 - loss: 0.49857
iteration: 14600 - loss: 0.52768
iteration: 14650 - loss: 0.50919
iteration: 14700 - loss: 0.51429
iteration: 14750 - loss: 0.54715
iteration: 14800 - loss: 0.51875
iteration: 14850 - loss: 0.45628
iteration: 14900 - loss: 0.50392
iteration: 14950 - loss: 0.59678
iteration: 15000 - loss: 0.53131
iteration: 15050 - loss: 0.48087
iteration: 15100 - loss: 0.52759
iteration: 15150 - loss: 0.51634
iteration: 15200 - loss: 0.52555
iteration: 15250 - loss: 0.53735
iteration: 15300 - loss: 0.51387
iteration: 15350 - loss: 0.51610
iteration: 15400 - loss: 0.55244
iteration: 15450 - loss: 0.50871
iteration: 15500 - loss: 0.50197
iteration: 15550 - loss: 0.47981
iteration: 15600 - loss: 0.49676
iteration: 15650 - loss: 0.53263
iteration: 15700 - loss: 0.56217
iteration: 15750 - loss: 0.52915
iteration: 15800 - loss: 0.47352
iteration: 15850 - loss: 0.54113
iteration: 15900 - loss: 0.54051
iteration: 15950 - loss: 0.51728
iteration: 16000 - loss: 0.52612
iteration: 16050 - loss: 0.50962
iteration: 16100 - loss: 0.50851
iteration: 16150 - loss: 0.53108
iteration: 16200 - loss: 0.51035
iteration: 16250 - loss: 0.53265
iteration: 16300 - loss: 0.45993
iteration: 16350 - loss: 0.54391
iteration: 16400 - loss: 0.55968
iteration: 16450 - loss: 0.51773
iteration: 16500 - loss: 0.51457
iteration: 16550 - loss: 0.50862
iteration: 16600 - loss: 0.54185
iteration: 16650 - loss: 0.49691
iteration: 16700 - loss: 0.50887
iteration: 16750 - loss: 0.53466
iteration: 16800 - loss: 0.52565
iteration: 16850 - loss: 0.54270
iteration: 16900 - loss: 0.50653
iteration: 16950 - loss: 0.50248
iteration: 17000 - loss: 0.52226
iteration: 17050 - loss: 0.55674
iteration: 17100 - loss: 0.50684
iteration: 17150 - loss: 0.53973
iteration: 17200 - loss: 0.48723
iteration: 17250 - loss: 0.50801
iteration: 17300 - loss: 0.48118
iteration: 17350 - loss: 0.48330
iteration: 17400 - loss: 0.53349
iteration: 17450 - loss: 0.55945
iteration: 17500 - loss: 0.54210
iteration: 17550 - loss: 0.47488
iteration: 17600 - loss: 0.50823
iteration: 17650 - loss: 0.51776
iteration: 17700 - loss: 0.55980
iteration: 17750 - loss: 0.53743
iteration: 17800 - loss: 0.53095
iteration: 17850 - loss: 0.51411
iteration: 17900 - loss: 0.53202
iteration: 17950 - loss: 0.50280
iteration: 18000 - loss: 0.51419
iteration: 18050 - loss: 0.51497
iteration: 18100 - loss: 0.51719
iteration: 18150 - loss: 0.52197
iteration: 18200 - loss: 0.51126
iteration: 18250 - loss: 0.52755
iteration: 18300 - loss: 0.46401
iteration: 18350 - loss: 0.49378
iteration: 18400 - loss: 0.49710
iteration: 18450 - loss: 0.57560
iteration: 18500 - loss: 0.56699
iteration: 18550 - loss: 0.49968
iteration: 18600 - loss: 0.55099
iteration: 18650 - loss: 0.50512
iteration: 18700 - loss: 0.50689
iteration: 18750 - loss: 0.52589
iteration: 18800 - loss: 0.54754
iteration: 18850 - loss: 0.51068
iteration: 18900 - loss: 0.54746
iteration: 18950 - loss: 0.47942
iteration: 19000 - loss: 0.51101
iteration: 19050 - loss: 0.48238
iteration: 19100 - loss: 0.53267
iteration: 19150 - loss: 0.53562
iteration: 19200 - loss: 0.51768
iteration: 19250 - loss: 0.52900
iteration: 19300 - loss: 0.48399
iteration: 19350 - loss: 0.49039
iteration: 19400 - loss: 0.53881
iteration: 19450 - loss: 0.57972
iteration: 19500 - loss: 0.51076
iteration: 19550 - loss: 0.51226
iteration: 19600 - loss: 0.52324
iteration: 19650 - loss: 0.50216
iteration: 19700 - loss: 0.50125
iteration: 19750 - loss: 0.54688
iteration: 19800 - loss: 0.53856
iteration: 19850 - loss: 0.50915
iteration: 19900 - loss: 0.49954
iteration: 19950 - loss: 0.55037
iteration: 20000 - loss: 0.50585
iteration: 20050 - loss: 0.51426
iteration: 20100 - loss: 0.53030
iteration: 20150 - loss: 0.54730
iteration: 20200 - loss: 0.48470
iteration: 20250 - loss: 0.50696
iteration: 20300 - loss: 0.49011
iteration: 20350 - loss: 0.49658
iteration: 20400 - loss: 0.49779
iteration: 20450 - loss: 0.54181
iteration: 20500 - loss: 0.57443
iteration: 20550 - loss: 0.51036
iteration: 20600 - loss: 0.53521
iteration: 20650 - loss: 0.51430
iteration: 20700 - loss: 0.50284
iteration: 20750 - loss: 0.52753
iteration: 20800 - loss: 0.49211
iteration: 20850 - loss: 0.51101
iteration: 20900 - loss: 0.50408
iteration: 20950 - loss: 0.55335
iteration: 21000 - loss: 0.53322
iteration: 21050 - loss: 0.50461
iteration: 21100 - loss: 0.53904
iteration: 21150 - loss: 0.48599
iteration: 21200 - loss: 0.53982
iteration: 21250 - loss: 0.52755
iteration: 21300 - loss: 0.48918
iteration: 21350 - loss: 0.51473
iteration: 21400 - loss: 0.53835
iteration: 21450 - loss: 0.51444
iteration: 21500 - loss: 0.54913
iteration: 21550 - loss: 0.50090
iteration: 21600 - loss: 0.52636
iteration: 21650 - loss: 0.53858
iteration: 21700 - loss: 0.46554
iteration: 21750 - loss: 0.56520
iteration: 21800 - loss: 0.52128
iteration: 21850 - loss: 0.54187
iteration: 21900 - loss: 0.48709
iteration: 21950 - loss: 0.52132
iteration: 22000 - loss: 0.51468
iteration: 22050 - loss: 0.52694
iteration: 22100 - loss: 0.52088
iteration: 22150 - loss: 0.49705
iteration: 22200 - loss: 0.53451
iteration: 22250 - loss: 0.51501
iteration: 22300 - loss: 0.51838
iteration: 22350 - loss: 0.52502
iteration: 22400 - loss: 0.49580
iteration: 22450 - loss: 0.54071
iteration: 22500 - loss: 0.51146
iteration: 22550 - loss: 0.51509
iteration: 22600 - loss: 0.47346
iteration: 22650 - loss: 0.53578
iteration: 22700 - loss: 0.53559
iteration: 22750 - loss: 0.53610
iteration: 22800 - loss: 0.51000
iteration: 22850 - loss: 0.49376
iteration: 22900 - loss: 0.50807
iteration: 22950 - loss: 0.55181
iteration: 23000 - loss: 0.52757
iteration: 23050 - loss: 0.49917
iteration: 23100 - loss: 0.51007
iteration: 23150 - loss: 0.50868
iteration: 23200 - loss: 0.55421
iteration: 23250 - loss: 0.52380
iteration: 23300 - loss: 0.50584
iteration: 23350 - loss: 0.52285
iteration: 23400 - loss: 0.53240
iteration: 23450 - loss: 0.52224
iteration: 23500 - loss: 0.50692
iteration: 23550 - loss: 0.54241
iteration: 23600 - loss: 0.49699
iteration: 23650 - loss: 0.49410
iteration: 23700 - loss: 0.54031
iteration: 23750 - loss: 0.53214
iteration: 23800 - loss: 0.47982
iteration: 23850 - loss: 0.52294
iteration: 23900 - loss: 0.55180
iteration: 23950 - loss: 0.53026
iteration: 24000 - loss: 0.50271
iteration: 24050 - loss: 0.53458
iteration: 24100 - loss: 0.48355
iteration: 24150 - loss: 0.49789
iteration: 24200 - loss: 0.52799
iteration: 24250 - loss: 0.55507
iteration: 24300 - loss: 0.52010
iteration: 24350 - loss: 0.49583
iteration: 24400 - loss: 0.53866
iteration: 24450 - loss: 0.55186
iteration: 24500 - loss: 0.48483
iteration: 24550 - loss: 0.53275
iteration: 24600 - loss: 0.50936
iteration: 24650 - loss: 0.47327
iteration: 24700 - loss: 0.55780
iteration: 24750 - loss: 0.52221
iteration: 24800 - loss: 0.50742
iteration: 24850 - loss: 0.50482
iteration: 24900 - loss: 0.53179
iteration: 24950 - loss: 0.51185
rmse: 1.0324
dcg: 10.4436
Reading dataset
Dataset read complete...
n users: 75
n items: 3287
Model intialized
Beginning Training...
cuda
mse loss
Training on GPU: 1 devices
iteration: 0 - loss: 13.38134
iteration: 50 - loss: 13.92866
iteration: 100 - loss: 13.79962
iteration: 150 - loss: 13.74166
iteration: 200 - loss: 13.79921
iteration: 250 - loss: 13.31889
iteration: 300 - loss: 13.21929
iteration: 350 - loss: 12.70348
iteration: 400 - loss: 12.18533
iteration: 450 - loss: 11.21437
iteration: 500 - loss: 9.91610
iteration: 550 - loss: 8.15464
iteration: 600 - loss: 5.95415
iteration: 650 - loss: 4.18857
iteration: 700 - loss: 2.67111
iteration: 750 - loss: 1.71042
iteration: 800 - loss: 1.18283
iteration: 850 - loss: 0.93072
iteration: 900 - loss: 1.01771
iteration: 950 - loss: 0.90888
iteration: 1000 - loss: 0.93715
iteration: 1050 - loss: 0.91691
iteration: 1100 - loss: 0.91882
iteration: 1150 - loss: 0.88232
iteration: 1200 - loss: 0.88468
iteration: 1250 - loss: 0.84872
iteration: 1300 - loss: 0.85597
iteration: 1350 - loss: 0.85044
iteration: 1400 - loss: 0.89981
iteration: 1450 - loss: 0.82335
iteration: 1500 - loss: 0.86049
iteration: 1550 - loss: 0.84429
iteration: 1600 - loss: 0.82660
iteration: 1650 - loss: 0.79180
iteration: 1700 - loss: 0.84403
iteration: 1750 - loss: 0.84160
iteration: 1800 - loss: 0.81806
iteration: 1850 - loss: 0.81179
iteration: 1900 - loss: 0.83079
iteration: 1950 - loss: 0.75196
iteration: 2000 - loss: 0.80061
iteration: 2050 - loss: 0.79897
iteration: 2100 - loss: 0.73525
iteration: 2150 - loss: 0.81390
iteration: 2200 - loss: 0.79906
iteration: 2250 - loss: 0.75021
iteration: 2300 - loss: 0.72334
iteration: 2350 - loss: 0.74715
iteration: 2400 - loss: 0.78789
iteration: 2450 - loss: 0.78266
iteration: 2500 - loss: 0.74947
iteration: 2550 - loss: 0.75003
iteration: 2600 - loss: 0.70896
iteration: 2650 - loss: 0.70053
iteration: 2700 - loss: 0.77789
iteration: 2750 - loss: 0.75457
iteration: 2800 - loss: 0.74621
iteration: 2850 - loss: 0.70460
iteration: 2900 - loss: 0.73541
iteration: 2950 - loss: 0.68820
iteration: 3000 - loss: 0.71694
iteration: 3050 - loss: 0.67924
iteration: 3100 - loss: 0.70904
iteration: 3150 - loss: 0.68778
iteration: 3200 - loss: 0.75553
iteration: 3250 - loss: 0.67592
iteration: 3300 - loss: 0.70684
iteration: 3350 - loss: 0.67505
iteration: 3400 - loss: 0.71367
iteration: 3450 - loss: 0.68153
iteration: 3500 - loss: 0.65243
iteration: 3550 - loss: 0.64050
iteration: 3600 - loss: 0.63464
iteration: 3650 - loss: 0.70141
iteration: 3700 - loss: 0.70643
iteration: 3750 - loss: 0.66469
iteration: 3800 - loss: 0.61225
iteration: 3850 - loss: 0.65447
iteration: 3900 - loss: 0.70298
iteration: 3950 - loss: 0.63192
iteration: 4000 - loss: 0.66094
iteration: 4050 - loss: 0.60503
iteration: 4100 - loss: 0.69180
iteration: 4150 - loss: 0.63295
iteration: 4200 - loss: 0.63046
iteration: 4250 - loss: 0.64693
iteration: 4300 - loss: 0.64970
iteration: 4350 - loss: 0.60183
iteration: 4400 - loss: 0.61483
iteration: 4450 - loss: 0.61227
iteration: 4500 - loss: 0.66167
iteration: 4550 - loss: 0.59361
iteration: 4600 - loss: 0.63126
iteration: 4650 - loss: 0.61188
iteration: 4700 - loss: 0.62707
iteration: 4750 - loss: 0.62589
iteration: 4800 - loss: 0.57645
iteration: 4850 - loss: 0.58749
iteration: 4900 - loss: 0.62583
iteration: 4950 - loss: 0.62799
iteration: 5000 - loss: 0.61287
iteration: 5050 - loss: 0.57151
iteration: 5100 - loss: 0.58783
iteration: 5150 - loss: 0.60481
iteration: 5200 - loss: 0.61396
iteration: 5250 - loss: 0.61062
iteration: 5300 - loss: 0.55281
iteration: 5350 - loss: 0.61812
iteration: 5400 - loss: 0.61212
iteration: 5450 - loss: 0.59461
iteration: 5500 - loss: 0.55983
iteration: 5550 - loss: 0.58586
iteration: 5600 - loss: 0.58908
iteration: 5650 - loss: 0.55983
iteration: 5700 - loss: 0.57811
iteration: 5750 - loss: 0.59455
iteration: 5800 - loss: 0.59587
iteration: 5850 - loss: 0.55534
iteration: 5900 - loss: 0.57465
iteration: 5950 - loss: 0.59373
iteration: 6000 - loss: 0.54498
iteration: 6050 - loss: 0.54143
iteration: 6100 - loss: 0.55512
iteration: 6150 - loss: 0.56313
iteration: 6200 - loss: 0.58835
iteration: 6250 - loss: 0.58034
iteration: 6300 - loss: 0.56351
iteration: 6350 - loss: 0.54873
iteration: 6400 - loss: 0.54088
iteration: 6450 - loss: 0.58674
iteration: 6500 - loss: 0.56409
iteration: 6550 - loss: 0.53376
iteration: 6600 - loss: 0.53733
iteration: 6650 - loss: 0.55195
iteration: 6700 - loss: 0.60333
iteration: 6750 - loss: 0.55501
iteration: 6800 - loss: 0.55642
iteration: 6850 - loss: 0.52900
iteration: 6900 - loss: 0.53523
iteration: 6950 - loss: 0.53584
iteration: 7000 - loss: 0.60125
iteration: 7050 - loss: 0.52528
iteration: 7100 - loss: 0.56327
iteration: 7150 - loss: 0.51404
iteration: 7200 - loss: 0.54851
iteration: 7250 - loss: 0.58205
iteration: 7300 - loss: 0.53686
iteration: 7350 - loss: 0.54572
iteration: 7400 - loss: 0.55368
iteration: 7450 - loss: 0.55013
iteration: 7500 - loss: 0.54702
iteration: 7550 - loss: 0.53140
iteration: 7600 - loss: 0.53039
iteration: 7650 - loss: 0.55234
iteration: 7700 - loss: 0.56464
iteration: 7750 - loss: 0.51312
iteration: 7800 - loss: 0.55939
iteration: 7850 - loss: 0.53644
iteration: 7900 - loss: 0.54061
iteration: 7950 - loss: 0.52804
iteration: 8000 - loss: 0.52752
iteration: 8050 - loss: 0.52886
iteration: 8100 - loss: 0.51628
iteration: 8150 - loss: 0.57135
iteration: 8200 - loss: 0.52856
iteration: 8250 - loss: 0.53726
iteration: 8300 - loss: 0.53031
iteration: 8350 - loss: 0.55467
iteration: 8400 - loss: 0.52532
iteration: 8450 - loss: 0.53501
iteration: 8500 - loss: 0.52356
iteration: 8550 - loss: 0.51659
iteration: 8600 - loss: 0.52457
iteration: 8650 - loss: 0.51861
iteration: 8700 - loss: 0.52697
iteration: 8750 - loss: 0.57994
iteration: 8800 - loss: 0.53774
iteration: 8850 - loss: 0.51442
iteration: 8900 - loss: 0.54852
iteration: 8950 - loss: 0.49820
iteration: 9000 - loss: 0.55291
iteration: 9050 - loss: 0.49089
iteration: 9100 - loss: 0.57946
iteration: 9150 - loss: 0.55238
iteration: 9200 - loss: 0.47709
iteration: 9250 - loss: 0.54166
iteration: 9300 - loss: 0.52973
iteration: 9350 - loss: 0.53528
iteration: 9400 - loss: 0.52214
iteration: 9450 - loss: 0.53629
iteration: 9500 - loss: 0.52018
iteration: 9550 - loss: 0.54062
iteration: 9600 - loss: 0.47591
iteration: 9650 - loss: 0.54420
iteration: 9700 - loss: 0.51891
iteration: 9750 - loss: 0.54837
iteration: 9800 - loss: 0.56824
iteration: 9850 - loss: 0.50975
iteration: 9900 - loss: 0.49573
iteration: 9950 - loss: 0.53233
iteration: 10000 - loss: 0.52487
iteration: 10050 - loss: 0.51356
iteration: 10100 - loss: 0.48497
iteration: 10150 - loss: 0.52534
iteration: 10200 - loss: 0.56631
iteration: 10250 - loss: 0.52651
iteration: 10300 - loss: 0.50393
iteration: 10350 - loss: 0.54662
iteration: 10400 - loss: 0.51114
iteration: 10450 - loss: 0.52096
iteration: 10500 - loss: 0.53678
iteration: 10550 - loss: 0.53162
iteration: 10600 - loss: 0.53777
iteration: 10650 - loss: 0.49929
iteration: 10700 - loss: 0.54025
iteration: 10750 - loss: 0.50821
iteration: 10800 - loss: 0.53846
iteration: 10850 - loss: 0.53375
iteration: 10900 - loss: 0.51901
iteration: 10950 - loss: 0.51876
iteration: 11000 - loss: 0.50172
iteration: 11050 - loss: 0.48182
iteration: 11100 - loss: 0.54087
iteration: 11150 - loss: 0.53654
iteration: 11200 - loss: 0.53906
iteration: 11250 - loss: 0.51081
iteration: 11300 - loss: 0.50132
iteration: 11350 - loss: 0.56245
iteration: 11400 - loss: 0.52161
iteration: 11450 - loss: 0.50723
iteration: 11500 - loss: 0.52215
iteration: 11550 - loss: 0.51154
iteration: 11600 - loss: 0.49898
iteration: 11650 - loss: 0.55068
iteration: 11700 - loss: 0.51060
iteration: 11750 - loss: 0.52575
iteration: 11800 - loss: 0.53328
iteration: 11850 - loss: 0.53726
iteration: 11900 - loss: 0.50199
iteration: 11950 - loss: 0.48727
iteration: 12000 - loss: 0.54502
iteration: 12050 - loss: 0.50174
iteration: 12100 - loss: 0.51718
iteration: 12150 - loss: 0.53928
iteration: 12200 - loss: 0.53671
iteration: 12250 - loss: 0.50188
iteration: 12300 - loss: 0.54678
iteration: 12350 - loss: 0.48149
iteration: 12400 - loss: 0.51887
iteration: 12450 - loss: 0.52591
iteration: 12500 - loss: 0.53040
iteration: 12550 - loss: 0.52484
iteration: 12600 - loss: 0.52559
iteration: 12650 - loss: 0.52138
iteration: 12700 - loss: 0.50391
iteration: 12750 - loss: 0.51868
iteration: 12800 - loss: 0.49011
iteration: 12850 - loss: 0.54459
iteration: 12900 - loss: 0.54645
iteration: 12950 - loss: 0.49780
iteration: 13000 - loss: 0.52644
iteration: 13050 - loss: 0.50539
iteration: 13100 - loss: 0.48926
iteration: 13150 - loss: 0.55555
iteration: 13200 - loss: 0.49313
iteration: 13250 - loss: 0.54898
iteration: 13300 - loss: 0.50904
iteration: 13350 - loss: 0.48371
iteration: 13400 - loss: 0.53191
iteration: 13450 - loss: 0.55530
iteration: 13500 - loss: 0.51272
iteration: 13550 - loss: 0.53146
iteration: 13600 - loss: 0.48363
iteration: 13650 - loss: 0.52261
iteration: 13700 - loss: 0.50073
iteration: 13750 - loss: 0.55600
iteration: 13800 - loss: 0.52941
iteration: 13850 - loss: 0.52135
iteration: 13900 - loss: 0.52870
iteration: 13950 - loss: 0.52119
iteration: 14000 - loss: 0.49697
iteration: 14050 - loss: 0.52528
iteration: 14100 - loss: 0.52734
iteration: 14150 - loss: 0.54588
iteration: 14200 - loss: 0.47983
iteration: 14250 - loss: 0.51585
iteration: 14300 - loss: 0.47882
iteration: 14350 - loss: 0.49770
iteration: 14400 - loss: 0.53516
iteration: 14450 - loss: 0.55025
iteration: 14500 - loss: 0.53381
iteration: 14550 - loss: 0.53468
iteration: 14600 - loss: 0.51156
iteration: 14650 - loss: 0.52142
iteration: 14700 - loss: 0.47844
iteration: 14750 - loss: 0.54740
iteration: 14800 - loss: 0.50979
iteration: 14850 - loss: 0.52257
iteration: 14900 - loss: 0.48866
iteration: 14950 - loss: 0.49520
iteration: 15000 - loss: 0.58433
iteration: 15050 - loss: 0.52304
iteration: 15100 - loss: 0.52894
iteration: 15150 - loss: 0.51127
iteration: 15200 - loss: 0.52811
iteration: 15250 - loss: 0.50801
iteration: 15300 - loss: 0.52551
iteration: 15350 - loss: 0.51893
iteration: 15400 - loss: 0.52752
iteration: 15450 - loss: 0.49929
iteration: 15500 - loss: 0.51438
iteration: 15550 - loss: 0.54873
iteration: 15600 - loss: 0.48539
iteration: 15650 - loss: 0.53947
iteration: 15700 - loss: 0.51994
iteration: 15750 - loss: 0.49803
iteration: 15800 - loss: 0.48734
iteration: 15850 - loss: 0.52560
iteration: 15900 - loss: 0.53338
iteration: 15950 - loss: 0.52594
iteration: 16000 - loss: 0.52709
iteration: 16050 - loss: 0.51067
iteration: 16100 - loss: 0.50828
iteration: 16150 - loss: 0.51334
iteration: 16200 - loss: 0.49152
iteration: 16250 - loss: 0.55938
iteration: 16300 - loss: 0.52266
iteration: 16350 - loss: 0.50994
iteration: 16400 - loss: 0.49488
iteration: 16450 - loss: 0.55669
iteration: 16500 - loss: 0.51019
iteration: 16550 - loss: 0.50288
iteration: 16600 - loss: 0.52660
iteration: 16650 - loss: 0.51227
iteration: 16700 - loss: 0.51240
iteration: 16750 - loss: 0.53618
iteration: 16800 - loss: 0.54602
iteration: 16850 - loss: 0.52314
iteration: 16900 - loss: 0.52497
iteration: 16950 - loss: 0.48291
iteration: 17000 - loss: 0.52271
iteration: 17050 - loss: 0.51746
iteration: 17100 - loss: 0.53283
iteration: 17150 - loss: 0.50748
iteration: 17200 - loss: 0.52415
iteration: 17250 - loss: 0.51298
iteration: 17300 - loss: 0.57611
iteration: 17350 - loss: 0.50445
iteration: 17400 - loss: 0.50753
iteration: 17450 - loss: 0.50636
iteration: 17500 - loss: 0.49482
iteration: 17550 - loss: 0.49817
iteration: 17600 - loss: 0.53186
iteration: 17650 - loss: 0.50701
iteration: 17700 - loss: 0.52860
iteration: 17750 - loss: 0.52882
iteration: 17800 - loss: 0.50290
iteration: 17850 - loss: 0.49574
iteration: 17900 - loss: 0.53327
iteration: 17950 - loss: 0.53634
iteration: 18000 - loss: 0.51788
iteration: 18050 - loss: 0.50540
iteration: 18100 - loss: 0.55232
iteration: 18150 - loss: 0.52033
iteration: 18200 - loss: 0.49751
iteration: 18250 - loss: 0.52338
iteration: 18300 - loss: 0.51911
iteration: 18350 - loss: 0.48642
iteration: 18400 - loss: 0.50700
iteration: 18450 - loss: 0.54246
iteration: 18500 - loss: 0.53672
iteration: 18550 - loss: 0.48094
iteration: 18600 - loss: 0.52549
iteration: 18650 - loss: 0.53648
iteration: 18700 - loss: 0.51956
iteration: 18750 - loss: 0.52855
iteration: 18800 - loss: 0.47942
iteration: 18850 - loss: 0.49964
iteration: 18900 - loss: 0.52598
iteration: 18950 - loss: 0.56833
iteration: 19000 - loss: 0.51861
iteration: 19050 - loss: 0.53198
iteration: 19100 - loss: 0.49445
iteration: 19150 - loss: 0.53382
iteration: 19200 - loss: 0.51836
iteration: 19250 - loss: 0.51352
iteration: 19300 - loss: 0.51214
iteration: 19350 - loss: 0.57202
iteration: 19400 - loss: 0.46756
iteration: 19450 - loss: 0.52603
iteration: 19500 - loss: 0.51874
iteration: 19550 - loss: 0.53099
iteration: 19600 - loss: 0.50779
iteration: 19650 - loss: 0.50712
iteration: 19700 - loss: 0.51818
iteration: 19750 - loss: 0.52907
iteration: 19800 - loss: 0.51603
iteration: 19850 - loss: 0.49419
iteration: 19900 - loss: 0.51621
iteration: 19950 - loss: 0.50249
iteration: 20000 - loss: 0.55283
iteration: 20050 - loss: 0.50695
iteration: 20100 - loss: 0.49112
iteration: 20150 - loss: 0.50575
iteration: 20200 - loss: 0.54434
iteration: 20250 - loss: 0.54459
iteration: 20300 - loss: 0.51586
iteration: 20350 - loss: 0.52149
iteration: 20400 - loss: 0.48834
iteration: 20450 - loss: 0.50738
iteration: 20500 - loss: 0.56984
iteration: 20550 - loss: 0.50077
iteration: 20600 - loss: 0.49799
iteration: 20650 - loss: 0.50147
iteration: 20700 - loss: 0.51986
iteration: 20750 - loss: 0.56144
iteration: 20800 - loss: 0.48340
iteration: 20850 - loss: 0.51977
iteration: 20900 - loss: 0.52423
iteration: 20950 - loss: 0.51509
iteration: 21000 - loss: 0.54845
iteration: 21050 - loss: 0.53587
iteration: 21100 - loss: 0.47523
iteration: 21150 - loss: 0.52797
iteration: 21200 - loss: 0.51338
iteration: 21250 - loss: 0.54218
iteration: 21300 - loss: 0.50983
iteration: 21350 - loss: 0.52178
iteration: 21400 - loss: 0.48998
iteration: 21450 - loss: 0.56517
iteration: 21500 - loss: 0.49887
iteration: 21550 - loss: 0.51428
iteration: 21600 - loss: 0.51742
iteration: 21650 - loss: 0.52785
iteration: 21700 - loss: 0.50975
iteration: 21750 - loss: 0.53524
iteration: 21800 - loss: 0.51340
iteration: 21850 - loss: 0.51841
iteration: 21900 - loss: 0.52982
iteration: 21950 - loss: 0.48905
iteration: 22000 - loss: 0.53127
iteration: 22050 - loss: 0.50859
iteration: 22100 - loss: 0.50383
iteration: 22150 - loss: 0.50272
iteration: 22200 - loss: 0.55169
iteration: 22250 - loss: 0.52130
iteration: 22300 - loss: 0.48442
iteration: 22350 - loss: 0.50611
iteration: 22400 - loss: 0.51836
iteration: 22450 - loss: 0.53519
iteration: 22500 - loss: 0.54257
iteration: 22550 - loss: 0.47282
iteration: 22600 - loss: 0.52208
iteration: 22650 - loss: 0.52767
iteration: 22700 - loss: 0.53600
iteration: 22750 - loss: 0.53670
iteration: 22800 - loss: 0.48699
iteration: 22850 - loss: 0.53163
iteration: 22900 - loss: 0.50162
iteration: 22950 - loss: 0.53434
iteration: 23000 - loss: 0.53668
iteration: 23050 - loss: 0.46947
iteration: 23100 - loss: 0.54061
iteration: 23150 - loss: 0.52489
iteration: 23200 - loss: 0.49265
iteration: 23250 - loss: 0.56299
iteration: 23300 - loss: 0.51216
iteration: 23350 - loss: 0.54549
iteration: 23400 - loss: 0.52810
iteration: 23450 - loss: 0.50902
iteration: 23500 - loss: 0.50205
iteration: 23550 - loss: 0.48678
iteration: 23600 - loss: 0.52451
iteration: 23650 - loss: 0.51251
iteration: 23700 - loss: 0.53420
iteration: 23750 - loss: 0.52485
iteration: 23800 - loss: 0.47044
iteration: 23850 - loss: 0.48707
iteration: 23900 - loss: 0.52767
iteration: 23950 - loss: 0.55281
iteration: 24000 - loss: 0.55573
iteration: 24050 - loss: 0.50519
iteration: 24100 - loss: 0.52914
iteration: 24150 - loss: 0.50802
iteration: 24200 - loss: 0.51245
iteration: 24250 - loss: 0.53505
iteration: 24300 - loss: 0.46080
iteration: 24350 - loss: 0.52184
iteration: 24400 - loss: 0.53034
iteration: 24450 - loss: 0.54946
iteration: 24500 - loss: 0.52968
iteration: 24550 - loss: 0.52095
iteration: 24600 - loss: 0.52315
iteration: 24650 - loss: 0.52537
iteration: 24700 - loss: 0.50810
iteration: 24750 - loss: 0.51119
iteration: 24800 - loss: 0.50494
iteration: 24850 - loss: 0.51203
iteration: 24900 - loss: 0.49817
iteration: 24950 - loss: 0.54783
rmse: 1.0437
dcg: 10.3752
Reading dataset
Dataset read complete...
n users: 75
n items: 3287
Model intialized
Beginning Training...
cuda
mse loss
Training on GPU: 1 devices
iteration: 0 - loss: 12.92519
iteration: 50 - loss: 14.04329
iteration: 100 - loss: 13.93928
iteration: 150 - loss: 13.90965
iteration: 200 - loss: 13.72676
iteration: 250 - loss: 13.69213
iteration: 300 - loss: 13.33401
iteration: 350 - loss: 13.24669
iteration: 400 - loss: 12.17586
iteration: 450 - loss: 11.06962
iteration: 500 - loss: 9.58035
iteration: 550 - loss: 7.73097
iteration: 600 - loss: 5.37368
iteration: 650 - loss: 3.50656
iteration: 700 - loss: 2.09841
iteration: 750 - loss: 1.37488
iteration: 800 - loss: 0.98379
iteration: 850 - loss: 0.97238
iteration: 900 - loss: 0.95808
iteration: 950 - loss: 0.90049
iteration: 1000 - loss: 0.92615
iteration: 1050 - loss: 0.87858
iteration: 1100 - loss: 0.87857
iteration: 1150 - loss: 0.87224
iteration: 1200 - loss: 0.87939
iteration: 1250 - loss: 0.91719
iteration: 1300 - loss: 0.84181
iteration: 1350 - loss: 0.84588
iteration: 1400 - loss: 0.82262
iteration: 1450 - loss: 0.88337
iteration: 1500 - loss: 0.86491
iteration: 1550 - loss: 0.82381
iteration: 1600 - loss: 0.83544
iteration: 1650 - loss: 0.84672
iteration: 1700 - loss: 0.83468
iteration: 1750 - loss: 0.77195
iteration: 1800 - loss: 0.76149
iteration: 1850 - loss: 0.78152
iteration: 1900 - loss: 0.80372
iteration: 1950 - loss: 0.82478
iteration: 2000 - loss: 0.81662
iteration: 2050 - loss: 0.78677
iteration: 2100 - loss: 0.74893
iteration: 2150 - loss: 0.75973
iteration: 2200 - loss: 0.77609
iteration: 2250 - loss: 0.77585
iteration: 2300 - loss: 0.75268
iteration: 2350 - loss: 0.78459
iteration: 2400 - loss: 0.71584
iteration: 2450 - loss: 0.73624
iteration: 2500 - loss: 0.77341
iteration: 2550 - loss: 0.74798
iteration: 2600 - loss: 0.71454
iteration: 2650 - loss: 0.75352
iteration: 2700 - loss: 0.73173
iteration: 2750 - loss: 0.69020
iteration: 2800 - loss: 0.66685
iteration: 2850 - loss: 0.69803
iteration: 2900 - loss: 0.76619
iteration: 2950 - loss: 0.68248
iteration: 3000 - loss: 0.74474
iteration: 3050 - loss: 0.67045
iteration: 3100 - loss: 0.67563
iteration: 3150 - loss: 0.72571
iteration: 3200 - loss: 0.72975
iteration: 3250 - loss: 0.66707
iteration: 3300 - loss: 0.66461
iteration: 3350 - loss: 0.72137
iteration: 3400 - loss: 0.66056
iteration: 3450 - loss: 0.68682
iteration: 3500 - loss: 0.64460
iteration: 3550 - loss: 0.67593
iteration: 3600 - loss: 0.66066
iteration: 3650 - loss: 0.61361
iteration: 3700 - loss: 0.64802
iteration: 3750 - loss: 0.70125
iteration: 3800 - loss: 0.62578
iteration: 3850 - loss: 0.64769
iteration: 3900 - loss: 0.63641
iteration: 3950 - loss: 0.66210
iteration: 4000 - loss: 0.65629
iteration: 4050 - loss: 0.64089
iteration: 4100 - loss: 0.59675
iteration: 4150 - loss: 0.64627
iteration: 4200 - loss: 0.60776
iteration: 4250 - loss: 0.67887
iteration: 4300 - loss: 0.63157
iteration: 4350 - loss: 0.62301
iteration: 4400 - loss: 0.60138
iteration: 4450 - loss: 0.64777
iteration: 4500 - loss: 0.60023
iteration: 4550 - loss: 0.59144
iteration: 4600 - loss: 0.62492
iteration: 4650 - loss: 0.61077
iteration: 4700 - loss: 0.62815
iteration: 4750 - loss: 0.59327
iteration: 4800 - loss: 0.57637
iteration: 4850 - loss: 0.60706
iteration: 4900 - loss: 0.63024
iteration: 4950 - loss: 0.58612
iteration: 5000 - loss: 0.59727
iteration: 5050 - loss: 0.55821
iteration: 5100 - loss: 0.56840
iteration: 5150 - loss: 0.59889
iteration: 5200 - loss: 0.60721
iteration: 5250 - loss: 0.61187
iteration: 5300 - loss: 0.59281
iteration: 5350 - loss: 0.56702
iteration: 5400 - loss: 0.58150
iteration: 5450 - loss: 0.60453
iteration: 5500 - loss: 0.55425
iteration: 5550 - loss: 0.57967
iteration: 5600 - loss: 0.56341
iteration: 5650 - loss: 0.58123
iteration: 5700 - loss: 0.58464
iteration: 5750 - loss: 0.55932
iteration: 5800 - loss: 0.53658
iteration: 5850 - loss: 0.50460
iteration: 5900 - loss: 0.58819
iteration: 5950 - loss: 0.62613
iteration: 6000 - loss: 0.57953
iteration: 6050 - loss: 0.57143
iteration: 6100 - loss: 0.58239
iteration: 6150 - loss: 0.57001
iteration: 6200 - loss: 0.55856
iteration: 6250 - loss: 0.52375
iteration: 6300 - loss: 0.54974
iteration: 6350 - loss: 0.55279
iteration: 6400 - loss: 0.55381
iteration: 6450 - loss: 0.56971
iteration: 6500 - loss: 0.55863
iteration: 6550 - loss: 0.51048
iteration: 6600 - loss: 0.58545
iteration: 6650 - loss: 0.56222
iteration: 6700 - loss: 0.56011
iteration: 6750 - loss: 0.53667
iteration: 6800 - loss: 0.52692
iteration: 6850 - loss: 0.51569
iteration: 6900 - loss: 0.54983
iteration: 6950 - loss: 0.57977
iteration: 7000 - loss: 0.56912
iteration: 7050 - loss: 0.58758
iteration: 7100 - loss: 0.51751
iteration: 7150 - loss: 0.56219
iteration: 7200 - loss: 0.56111
iteration: 7250 - loss: 0.48795
iteration: 7300 - loss: 0.52873
iteration: 7350 - loss: 0.54515
iteration: 7400 - loss: 0.51835
iteration: 7450 - loss: 0.57720
iteration: 7500 - loss: 0.53784
iteration: 7550 - loss: 0.52635
iteration: 7600 - loss: 0.52537
iteration: 7650 - loss: 0.54224
iteration: 7700 - loss: 0.55640
iteration: 7750 - loss: 0.54343
iteration: 7800 - loss: 0.53730
iteration: 7850 - loss: 0.54562
iteration: 7900 - loss: 0.53140
iteration: 7950 - loss: 0.55425
iteration: 8000 - loss: 0.50610
iteration: 8050 - loss: 0.53936
iteration: 8100 - loss: 0.48584
iteration: 8150 - loss: 0.53178
iteration: 8200 - loss: 0.55678
iteration: 8250 - loss: 0.55874
iteration: 8300 - loss: 0.49858
iteration: 8350 - loss: 0.51402
iteration: 8400 - loss: 0.52378
iteration: 8450 - loss: 0.55036
iteration: 8500 - loss: 0.56800
iteration: 8550 - loss: 0.52663
iteration: 8600 - loss: 0.52165
iteration: 8650 - loss: 0.54277
iteration: 8700 - loss: 0.51631
iteration: 8750 - loss: 0.54960
iteration: 8800 - loss: 0.49998
iteration: 8850 - loss: 0.53343
iteration: 8900 - loss: 0.58414
iteration: 8950 - loss: 0.51165
iteration: 9000 - loss: 0.51039
iteration: 9050 - loss: 0.52971
iteration: 9100 - loss: 0.54307
iteration: 9150 - loss: 0.52000
iteration: 9200 - loss: 0.50222
iteration: 9250 - loss: 0.54883
iteration: 9300 - loss: 0.49900
iteration: 9350 - loss: 0.52097
iteration: 9400 - loss: 0.51509
iteration: 9450 - loss: 0.55016
iteration: 9500 - loss: 0.54496
iteration: 9550 - loss: 0.54389
iteration: 9600 - loss: 0.52181
iteration: 9650 - loss: 0.49880
iteration: 9700 - loss: 0.51389
iteration: 9750 - loss: 0.54302
iteration: 9800 - loss: 0.50155
iteration: 9850 - loss: 0.55155
iteration: 9900 - loss: 0.54027
iteration: 9950 - loss: 0.54435
iteration: 10000 - loss: 0.48505
iteration: 10050 - loss: 0.55762
iteration: 10100 - loss: 0.50595
iteration: 10150 - loss: 0.50773
iteration: 10200 - loss: 0.47287
iteration: 10250 - loss: 0.57938
iteration: 10300 - loss: 0.52460
iteration: 10350 - loss: 0.51623
iteration: 10400 - loss: 0.52981
iteration: 10450 - loss: 0.54784
iteration: 10500 - loss: 0.50072
iteration: 10550 - loss: 0.50452
iteration: 10600 - loss: 0.50643
iteration: 10650 - loss: 0.51975
iteration: 10700 - loss: 0.51389
iteration: 10750 - loss: 0.57391
iteration: 10800 - loss: 0.50134
iteration: 10850 - loss: 0.52725
iteration: 10900 - loss: 0.52345
iteration: 10950 - loss: 0.51510
iteration: 11000 - loss: 0.53278
iteration: 11050 - loss: 0.50023
iteration: 11100 - loss: 0.53352
iteration: 11150 - loss: 0.56283
iteration: 11200 - loss: 0.51081
iteration: 11250 - loss: 0.49853
iteration: 11300 - loss: 0.52507
iteration: 11350 - loss: 0.51985
iteration: 11400 - loss: 0.53404
iteration: 11450 - loss: 0.52000
iteration: 11500 - loss: 0.50770
iteration: 11550 - loss: 0.55311
iteration: 11600 - loss: 0.53090
iteration: 11650 - loss: 0.50655
iteration: 11700 - loss: 0.52000
iteration: 11750 - loss: 0.49155
iteration: 11800 - loss: 0.52003
iteration: 11850 - loss: 0.52656
iteration: 11900 - loss: 0.52013
iteration: 11950 - loss: 0.50773
iteration: 12000 - loss: 0.53485
iteration: 12050 - loss: 0.50692
iteration: 12100 - loss: 0.55910
iteration: 12150 - loss: 0.52535
iteration: 12200 - loss: 0.51355
iteration: 12250 - loss: 0.48936
iteration: 12300 - loss: 0.50402
iteration: 12350 - loss: 0.51367
iteration: 12400 - loss: 0.54568
iteration: 12450 - loss: 0.52878
iteration: 12500 - loss: 0.51658
iteration: 12550 - loss: 0.54568
iteration: 12600 - loss: 0.47684
iteration: 12650 - loss: 0.52352
iteration: 12700 - loss: 0.53205
iteration: 12750 - loss: 0.51297
iteration: 12800 - loss: 0.49245
iteration: 12850 - loss: 0.53227
iteration: 12900 - loss: 0.52004
iteration: 12950 - loss: 0.54683
iteration: 13000 - loss: 0.51936
iteration: 13050 - loss: 0.49115
iteration: 13100 - loss: 0.51528
iteration: 13150 - loss: 0.49476
iteration: 13200 - loss: 0.54768
iteration: 13250 - loss: 0.54473
iteration: 13300 - loss: 0.50318
iteration: 13350 - loss: 0.54098
iteration: 13400 - loss: 0.53414
iteration: 13450 - loss: 0.51301
iteration: 13500 - loss: 0.50253
iteration: 13550 - loss: 0.48812
iteration: 13600 - loss: 0.50511
iteration: 13650 - loss: 0.51934
iteration: 13700 - loss: 0.54790
iteration: 13750 - loss: 0.53763
iteration: 13800 - loss: 0.51788
iteration: 13850 - loss: 0.52827
iteration: 13900 - loss: 0.54294
iteration: 13950 - loss: 0.49238
iteration: 14000 - loss: 0.51642
iteration: 14050 - loss: 0.52728
iteration: 14100 - loss: 0.50419
iteration: 14150 - loss: 0.54502
iteration: 14200 - loss: 0.52418
iteration: 14250 - loss: 0.50360
iteration: 14300 - loss: 0.52833
iteration: 14350 - loss: 0.49872
iteration: 14400 - loss: 0.56200
iteration: 14450 - loss: 0.50682
iteration: 14500 - loss: 0.48957
iteration: 14550 - loss: 0.48796
iteration: 14600 - loss: 0.54392
iteration: 14650 - loss: 0.49191
iteration: 14700 - loss: 0.55991
iteration: 14750 - loss: 0.52149
iteration: 14800 - loss: 0.48496
iteration: 14850 - loss: 0.52140
iteration: 14900 - loss: 0.53393
iteration: 14950 - loss: 0.51342
iteration: 15000 - loss: 0.54191
iteration: 15050 - loss: 0.54609
iteration: 15100 - loss: 0.50060
iteration: 15150 - loss: 0.55756
iteration: 15200 - loss: 0.51788
iteration: 15250 - loss: 0.46415
iteration: 15300 - loss: 0.54756
iteration: 15350 - loss: 0.51121
iteration: 15400 - loss: 0.50585
iteration: 15450 - loss: 0.51732
iteration: 15500 - loss: 0.51372
iteration: 15550 - loss: 0.50529
iteration: 15600 - loss: 0.52539
iteration: 15650 - loss: 0.49927
iteration: 15700 - loss: 0.54123
iteration: 15750 - loss: 0.52930
iteration: 15800 - loss: 0.49444
iteration: 15850 - loss: 0.52403
iteration: 15900 - loss: 0.49814
iteration: 15950 - loss: 0.52876
iteration: 16000 - loss: 0.54316
iteration: 16050 - loss: 0.54990
iteration: 16100 - loss: 0.50029
iteration: 16150 - loss: 0.49221
iteration: 16200 - loss: 0.52764
iteration: 16250 - loss: 0.53086
iteration: 16300 - loss: 0.53168
iteration: 16350 - loss: 0.52477
iteration: 16400 - loss: 0.51675
iteration: 16450 - loss: 0.49382
iteration: 16500 - loss: 0.53546
iteration: 16550 - loss: 0.48650
iteration: 16600 - loss: 0.49710
iteration: 16650 - loss: 0.53285
iteration: 16700 - loss: 0.54535
iteration: 16750 - loss: 0.52646
iteration: 16800 - loss: 0.50966
iteration: 16850 - loss: 0.50957
iteration: 16900 - loss: 0.53439
iteration: 16950 - loss: 0.52348
iteration: 17000 - loss: 0.51797
iteration: 17050 - loss: 0.52418
iteration: 17100 - loss: 0.53259
iteration: 17150 - loss: 0.49511
iteration: 17200 - loss: 0.54629
iteration: 17250 - loss: 0.49288
iteration: 17300 - loss: 0.51488
iteration: 17350 - loss: 0.49663
iteration: 17400 - loss: 0.51186
iteration: 17450 - loss: 0.52096
iteration: 17500 - loss: 0.56305
iteration: 17550 - loss: 0.50150
iteration: 17600 - loss: 0.48956
iteration: 17650 - loss: 0.51531
iteration: 17700 - loss: 0.53475
iteration: 17750 - loss: 0.54960
iteration: 17800 - loss: 0.49284
iteration: 17850 - loss: 0.50683
iteration: 17900 - loss: 0.56109
iteration: 17950 - loss: 0.51686
iteration: 18000 - loss: 0.51591
iteration: 18050 - loss: 0.49643
iteration: 18100 - loss: 0.50931
iteration: 18150 - loss: 0.50675
iteration: 18200 - loss: 0.49039
iteration: 18250 - loss: 0.59059
iteration: 18300 - loss: 0.50394
iteration: 18350 - loss: 0.50358
iteration: 18400 - loss: 0.52056
iteration: 18450 - loss: 0.51002
iteration: 18500 - loss: 0.55075
iteration: 18550 - loss: 0.52330
iteration: 18600 - loss: 0.54463
iteration: 18650 - loss: 0.53863
iteration: 18700 - loss: 0.49444
iteration: 18750 - loss: 0.50066
iteration: 18800 - loss: 0.51200
iteration: 18850 - loss: 0.51824
iteration: 18900 - loss: 0.51904
iteration: 18950 - loss: 0.53469
iteration: 19000 - loss: 0.50436
iteration: 19050 - loss: 0.50866
iteration: 19100 - loss: 0.49604
iteration: 19150 - loss: 0.52076
iteration: 19200 - loss: 0.54700
iteration: 19250 - loss: 0.53196
iteration: 19300 - loss: 0.47683
iteration: 19350 - loss: 0.52257
iteration: 19400 - loss: 0.53505
iteration: 19450 - loss: 0.51435
iteration: 19500 - loss: 0.53532
iteration: 19550 - loss: 0.52383
iteration: 19600 - loss: 0.54158
iteration: 19650 - loss: 0.56208
iteration: 19700 - loss: 0.46305
iteration: 19750 - loss: 0.50785
iteration: 19800 - loss: 0.52846
iteration: 19850 - loss: 0.48238
iteration: 19900 - loss: 0.57385
iteration: 19950 - loss: 0.51763
iteration: 20000 - loss: 0.49359
iteration: 20050 - loss: 0.51541
iteration: 20100 - loss: 0.50931
iteration: 20150 - loss: 0.48907
iteration: 20200 - loss: 0.56802
iteration: 20250 - loss: 0.51231
iteration: 20300 - loss: 0.53617
iteration: 20350 - loss: 0.49887
iteration: 20400 - loss: 0.52769
iteration: 20450 - loss: 0.49776
iteration: 20500 - loss: 0.53240
iteration: 20550 - loss: 0.50410
iteration: 20600 - loss: 0.52113
iteration: 20650 - loss: 0.51664
iteration: 20700 - loss: 0.51293
iteration: 20750 - loss: 0.53896
iteration: 20800 - loss: 0.50967
iteration: 20850 - loss: 0.55881
iteration: 20900 - loss: 0.51880
iteration: 20950 - loss: 0.47965
iteration: 21000 - loss: 0.52820
iteration: 21050 - loss: 0.50210
iteration: 21100 - loss: 0.49292
iteration: 21150 - loss: 0.55790
iteration: 21200 - loss: 0.50047
iteration: 21250 - loss: 0.54002
iteration: 21300 - loss: 0.50724
iteration: 21350 - loss: 0.51098
iteration: 21400 - loss: 0.52783
iteration: 21450 - loss: 0.52631
iteration: 21500 - loss: 0.52382
iteration: 21550 - loss: 0.49840
iteration: 21600 - loss: 0.49098
iteration: 21650 - loss: 0.54886
iteration: 21700 - loss: 0.52522
iteration: 21750 - loss: 0.52264
iteration: 21800 - loss: 0.51033
iteration: 21850 - loss: 0.52198
iteration: 21900 - loss: 0.55323
iteration: 21950 - loss: 0.51766
iteration: 22000 - loss: 0.50067
iteration: 22050 - loss: 0.52010
iteration: 22100 - loss: 0.52650
iteration: 22150 - loss: 0.49747
iteration: 22200 - loss: 0.52827
iteration: 22250 - loss: 0.52324
iteration: 22300 - loss: 0.52943
iteration: 22350 - loss: 0.49557
iteration: 22400 - loss: 0.50892
iteration: 22450 - loss: 0.51973
iteration: 22500 - loss: 0.52893
iteration: 22550 - loss: 0.50344
iteration: 22600 - loss: 0.50815
iteration: 22650 - loss: 0.50147
iteration: 22700 - loss: 0.56398
iteration: 22750 - loss: 0.51963
iteration: 22800 - loss: 0.53151
iteration: 22850 - loss: 0.53433
iteration: 22900 - loss: 0.53192
iteration: 22950 - loss: 0.49836
iteration: 23000 - loss: 0.49430
iteration: 23050 - loss: 0.53335
iteration: 23100 - loss: 0.51875
iteration: 23150 - loss: 0.50712
iteration: 23200 - loss: 0.51730
iteration: 23250 - loss: 0.52584
iteration: 23300 - loss: 0.54665
iteration: 23350 - loss: 0.49987
iteration: 23400 - loss: 0.52444
iteration: 23450 - loss: 0.49820
iteration: 23500 - loss: 0.52082
iteration: 23550 - loss: 0.46434
iteration: 23600 - loss: 0.50408
iteration: 23650 - loss: 0.55111
iteration: 23700 - loss: 0.52769
iteration: 23750 - loss: 0.54297
iteration: 23800 - loss: 0.51875
iteration: 23850 - loss: 0.51902
iteration: 23900 - loss: 0.56305
iteration: 23950 - loss: 0.44777
iteration: 24000 - loss: 0.54061
iteration: 24050 - loss: 0.51758
iteration: 24100 - loss: 0.49189
iteration: 24150 - loss: 0.54764
iteration: 24200 - loss: 0.49822
iteration: 24250 - loss: 0.54523
iteration: 24300 - loss: 0.53019
iteration: 24350 - loss: 0.50805
iteration: 24400 - loss: 0.52166
iteration: 24450 - loss: 0.51323
iteration: 24500 - loss: 0.51798
iteration: 24550 - loss: 0.52710
iteration: 24600 - loss: 0.50463
iteration: 24650 - loss: 0.51103
iteration: 24700 - loss: 0.53128
iteration: 24750 - loss: 0.52058
iteration: 24800 - loss: 0.49282
iteration: 24850 - loss: 0.51958
iteration: 24900 - loss: 0.52340
iteration: 24950 - loss: 0.52412
rmse: 1.0264
dcg: 10.4158
